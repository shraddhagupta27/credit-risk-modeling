{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9140122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55960359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "\n",
    "df1 = pd.read_excel('case_study1.xlsx')\n",
    "\n",
    "df2 = pd.read_excel('case_study2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2bcc7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 26)\n",
      "(51336, 62)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b0928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51296, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove nulls\n",
    "\n",
    "df1 = df1[df1['Age_Newest_TL'] != -99999]\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce82403d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_since_first_deliquency',\n",
       " 'time_since_recent_deliquency',\n",
       " 'max_delinquency_level',\n",
       " 'max_deliq_6mts',\n",
       " 'max_deliq_12mts',\n",
       " 'CC_utilization',\n",
       " 'PL_utilization',\n",
       " 'max_unsec_exposure_inPct']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns with more than 10k null values \n",
    "\n",
    "cols_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        cols_removed.append(i)\n",
    "\n",
    "cols_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb90800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51336, 54)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove cols with null values\n",
    "\n",
    "df2 = df2.drop(cols_removed, axis=1)\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93846d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42066, 54)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove null rows\n",
    "\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[df2[i] != -99999]\n",
    "\n",
    "df2.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da5b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID\n"
     ]
    }
   ],
   "source": [
    "# checking commom columns\n",
    "\n",
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b45815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42064, 79)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join both datasets\n",
    "\n",
    "df = df1.merge(df2, how='inner', on='PROSPECTID')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d360e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "# check categorical columns\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794a17c8-31b2-48fe-9dc3-0e048d6928a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Single']\n",
      "['12TH' 'GRADUATE' 'SSC' 'POST-GRADUATE' 'UNDER GRADUATE' 'OTHERS'\n",
      " 'PROFESSIONAL']\n",
      "['M' 'F']\n",
      "['PL' 'ConsumerLoan' 'AL' 'CC' 'others' 'HL']\n",
      "['PL' 'ConsumerLoan' 'others' 'AL' 'HL' 'CC']\n",
      "['P2' 'P1' 'P3' 'P4']\n"
     ]
    }
   ],
   "source": [
    "print(df['MARITALSTATUS'].unique())\n",
    "print(df['EDUCATION'].unique())\n",
    "print(df['GENDER'].unique())\n",
    "print(df['last_prod_enq2'].unique())\n",
    "print(df['first_prod_enq2'].unique())\n",
    "print(df['Approved_Flag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84efd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.5781808610388605e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.9079361001865664e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.849976105554191e-287\n"
     ]
    }
   ],
   "source": [
    "# chi-square test \n",
    "\n",
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, \"---\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all values less than equal to 0.05, will accept all \n",
    "# associated with target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71cd3b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total_TL',\n",
       " 'Tot_Closed_TL',\n",
       " 'Tot_Active_TL',\n",
       " 'Total_TL_opened_L6M',\n",
       " 'Tot_TL_closed_L6M',\n",
       " 'pct_tl_open_L6M',\n",
       " 'pct_tl_closed_L6M',\n",
       " 'pct_active_tl',\n",
       " 'pct_closed_tl',\n",
       " 'Total_TL_opened_L12M',\n",
       " 'Tot_TL_closed_L12M',\n",
       " 'pct_tl_open_L12M',\n",
       " 'pct_tl_closed_L12M',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'Auto_TL',\n",
       " 'CC_TL',\n",
       " 'Consumer_TL',\n",
       " 'Gold_TL',\n",
       " 'Home_TL',\n",
       " 'PL_TL',\n",
       " 'Secured_TL',\n",
       " 'Unsecured_TL',\n",
       " 'Other_TL',\n",
       " 'Age_Oldest_TL',\n",
       " 'Age_Newest_TL',\n",
       " 'time_since_recent_payment',\n",
       " 'num_times_delinquent',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'num_deliq_6mts',\n",
       " 'num_deliq_12mts',\n",
       " 'num_deliq_6_12mts',\n",
       " 'num_times_30p_dpd',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_std',\n",
       " 'num_std_6mts',\n",
       " 'num_std_12mts',\n",
       " 'num_sub',\n",
       " 'num_sub_6mts',\n",
       " 'num_sub_12mts',\n",
       " 'num_dbt',\n",
       " 'num_dbt_6mts',\n",
       " 'num_dbt_12mts',\n",
       " 'num_lss',\n",
       " 'num_lss_6mts',\n",
       " 'num_lss_12mts',\n",
       " 'recent_level_of_deliq',\n",
       " 'tot_enq',\n",
       " 'CC_enq',\n",
       " 'CC_enq_L6m',\n",
       " 'CC_enq_L12m',\n",
       " 'PL_enq',\n",
       " 'PL_enq_L6m',\n",
       " 'PL_enq_L12m',\n",
       " 'time_since_recent_enq',\n",
       " 'enq_L12m',\n",
       " 'enq_L6m',\n",
       " 'enq_L3m',\n",
       " 'AGE',\n",
       " 'NETMONTHLYINCOME',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'pct_of_active_TLs_ever',\n",
       " 'pct_opened_TLs_L6m_of_L12m',\n",
       " 'pct_currentBal_all_TL',\n",
       " 'CC_Flag',\n",
       " 'PL_Flag',\n",
       " 'pct_PL_enq_L6m_of_L12m',\n",
       " 'pct_CC_enq_L6m_of_L12m',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'HL_Flag',\n",
       " 'GL_Flag',\n",
       " 'Credit_Score']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check numerical columns\n",
    "\n",
    "num_cols = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID', 'Approved_Flag']:\n",
    "        num_cols.append(i)\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018344e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- inf\n",
      "0 --- 11.320180023967982\n",
      "0 --- 8.36369803500036\n",
      "0 --- 6.5206478777909425\n",
      "0 --- 5.14950161821261\n",
      "1 --- 2.611111040579735\n",
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477212\n",
      "2 --- 3.832800792153082\n",
      "3 --- 6.0996533816466405\n",
      "3 --- 5.581352009642814\n",
      "4 --- 1.9855843530987702\n",
      "5 --- inf\n",
      "5 --- 4.809538302819332\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588099946\n",
      "6 --- 4.384346405965575\n",
      "7 --- 3.0646584155234122\n",
      "8 --- 2.898639771299225\n",
      "9 --- 4.377876915347337\n",
      "10 --- 2.2078535836958486\n",
      "11 --- 4.916914200506877\n",
      "12 --- 5.214702030064743\n",
      "13 --- 3.3861625024231516\n",
      "14 --- 7.84058330947899\n",
      "14 --- 5.255034641721459\n",
      "15 --- inf\n",
      "15 --- 7.380634506427207\n",
      "15 --- 1.421005001517572\n",
      "16 --- 8.083255010190301\n",
      "16 --- 1.6241227524040012\n",
      "17 --- 7.257811920140015\n",
      "17 --- 15.596243832683006\n",
      "17 --- 1.825857047132431\n",
      "18 --- 1.5080839450032724\n",
      "19 --- 2.1720888348245815\n",
      "20 --- 2.6233975535272367\n",
      "21 --- 2.2959970812106216\n",
      "22 --- 7.360578319196457\n",
      "22 --- 2.1602387773102514\n",
      "23 --- 2.8686288267891493\n",
      "24 --- 6.458218003637239\n",
      "24 --- 2.847411886563821\n",
      "25 --- 4.753198156284062\n",
      "26 --- 16.22735475594819\n",
      "26 --- 6.424377256363831\n",
      "26 --- 8.887080381808696\n",
      "26 --- 2.3804746142952564\n",
      "27 --- 8.609513476514524\n",
      "27 --- 13.067550935476769\n",
      "27 --- 3.500040056654664\n",
      "28 --- 1.908795587481377\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.73048515371916\n",
      "29 --- 2.3538497522950457\n",
      "30 --- 22.104855915136543\n",
      "30 --- 2.797163963851296\n",
      "31 --- 3.4241712032177065\n",
      "32 --- 10.17502145445105\n",
      "32 --- 6.408710354561287\n",
      "32 --- 1.0011511962625617\n",
      "33 --- 3.06919730539727\n",
      "34 --- 2.8091261600643707\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593886\n",
      "35 --- 1.8331649740532123\n",
      "36 --- 1.5680839909542181\n",
      "37 --- 1.930757235381163\n",
      "38 --- 4.33126505664525\n",
      "39 --- 9.390334396150184\n"
     ]
    }
   ],
   "source": [
    "# VIF sequentially check\n",
    "\n",
    "vif_data = df[num_cols]\n",
    "total_cols = vif_data.shape[1]\n",
    "cols_to_keep = []\n",
    "col_index = 0\n",
    "\n",
    "for i in range(0, total_cols):\n",
    "    vif_value = variance_inflation_factor(vif_data, col_index)\n",
    "    print(col_index, \"---\", vif_value)\n",
    "\n",
    "    if vif_value <= 6:\n",
    "        cols_to_keep.append(num_cols[i])\n",
    "        col_index = col_index + 1\n",
    "\n",
    "    else: \n",
    "        vif_data = vif_data.drop(num_cols[i], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44a627ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7636086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check anova\n",
    "\n",
    "cols_to_keep_num = []\n",
    "\n",
    "for i in cols_to_keep:\n",
    "    a = list(df[i])\n",
    "    b = list(df['Approved_Flag'])\n",
    "\n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "    f_statistics, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        cols_to_keep_num.append(i)\n",
    "\n",
    "\n",
    "len(cols_to_keep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b5e8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the final features\n",
    "\n",
    "features = cols_to_keep_num + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9466464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDUCATION\n",
       "3    18931\n",
       "2    11703\n",
       "1     9532\n",
       "4     1898\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinal encoding for education\n",
    "\n",
    "df.loc[df['EDUCATION']=='SSC', ['EDUCATION']] = 1\n",
    "df.loc[df['EDUCATION']=='12TH', ['EDUCATION']] = 2\n",
    "df.loc[df['EDUCATION']=='UNDER GRADUATE', ['EDUCATION']] = 3\n",
    "df.loc[df['EDUCATION']=='GRADUATE', ['EDUCATION']] = 3\n",
    "df.loc[df['EDUCATION']=='POST-GRADUATE', ['EDUCATION']] = 4\n",
    "df.loc[df['EDUCATION']=='PROFESSIONAL', ['EDUCATION']] = 3\n",
    "df.loc[df['EDUCATION']=='OTHERS', ['EDUCATION']] = 1\n",
    "\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abebfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 51 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 5   CC_TL                         42064 non-null  int64  \n",
      " 6   Home_TL                       42064 non-null  int64  \n",
      " 7   PL_TL                         42064 non-null  int64  \n",
      " 8   Secured_TL                    42064 non-null  int64  \n",
      " 9   Unsecured_TL                  42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 12  Age_Newest_TL                 42064 non-null  int64  \n",
      " 13  time_since_recent_payment     42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 16  num_times_60p_dpd             42064 non-null  int64  \n",
      " 17  num_std_12mts                 42064 non-null  int64  \n",
      " 18  num_sub                       42064 non-null  int64  \n",
      " 19  num_sub_6mts                  42064 non-null  int64  \n",
      " 20  num_sub_12mts                 42064 non-null  int64  \n",
      " 21  num_dbt                       42064 non-null  int64  \n",
      " 22  num_dbt_12mts                 42064 non-null  int64  \n",
      " 23  num_lss                       42064 non-null  int64  \n",
      " 24  recent_level_of_deliq         42064 non-null  int64  \n",
      " 25  CC_enq_L12m                   42064 non-null  int64  \n",
      " 26  PL_enq_L12m                   42064 non-null  int64  \n",
      " 27  time_since_recent_enq         42064 non-null  int64  \n",
      " 28  enq_L3m                       42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 31  CC_Flag                       42064 non-null  int64  \n",
      " 32  PL_Flag                       42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  HL_Flag                       42064 non-null  int64  \n",
      " 36  GL_Flag                       42064 non-null  int64  \n",
      " 37  EDUCATION                     42064 non-null  int64  \n",
      " 38  Approved_Flag                 42064 non-null  object \n",
      " 39  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 40  GENDER_M                      42064 non-null  bool   \n",
      " 41  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 42  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 43  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 44  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 45  last_prod_enq2_others         42064 non-null  bool   \n",
      " 46  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 47  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 48  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 49  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 50  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(12), float64(5), int64(33), object(1)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding for other categorical columns\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2'], drop_first=True)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64238907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.7663140377986449\n",
      "\n",
      "Class p1\n",
      "Precision = 0.8411214953271028\n",
      "Recall = 0.7100591715976331\n",
      "F1_score = 0.7700534759358288\n",
      "\n",
      "Class p2\n",
      "Precision = 0.7974855589534489\n",
      "Recall = 0.930426164519326\n",
      "F1_score = 0.8588418259994511\n",
      "\n",
      "Class p3\n",
      "Precision = 0.4390625\n",
      "Recall = 0.2120754716981132\n",
      "F1_score = 0.2860050890585242\n",
      "\n",
      "Class p4\n",
      "Precision = 0.7293889427740058\n",
      "Recall = 0.7308066083576288\n",
      "F1_score = 0.7300970873786408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "rf_classifier.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b6b629f-e2a3-4a28-9174-2a5011094891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.707714251753239\n",
      "\n",
      "Class p1\n",
      "Precision = 0.7158098933074685\n",
      "Recall = 0.727810650887574\n",
      "F1_score = 0.721760391198044\n",
      "\n",
      "Class p2\n",
      "Precision = 0.8072805139186295\n",
      "Recall = 0.822001982160555\n",
      "F1_score = 0.8145747397367904\n",
      "\n",
      "Class p3\n",
      "Precision = 0.34269662921348315\n",
      "Recall = 0.3222641509433962\n",
      "F1_score = 0.33216647218980944\n",
      "\n",
      "Class p4\n",
      "Precision = 0.6426426426426426\n",
      "Recall = 0.6239067055393586\n",
      "F1_score = 0.6331360946745562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "\n",
    "dt_model.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcb5795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.7726138119576845\n",
      "\n",
      "Class p1\n",
      "Precision = 0.8232804232804233\n",
      "Recall = 0.7672583826429981\n",
      "F1_score = 0.7942827973455845\n",
      "\n",
      "Class p2\n",
      "Precision = 0.8261887608069164\n",
      "Recall = 0.9092170465807731\n",
      "F1_score = 0.8657167122770596\n",
      "\n",
      "Class p3\n",
      "Precision = 0.44532130777903045\n",
      "Recall = 0.2981132075471698\n",
      "F1_score = 0.35714285714285715\n",
      "\n",
      "Class p4\n",
      "Precision = 0.7191448007774538\n",
      "Recall = 0.7191448007774538\n",
      "F1_score = 0.7191448007774538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "499ce65f-e42f-4d8d-aeb9-dcde95a15189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-26 23:20:44,889]\u001b[0m A new study created in memory with name: no-name-b11bb279-206d-4525-8e66-a9637f3e0828\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:45,094]\u001b[0m Trial 0 finished with value: 0.7547842624509687 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 10, 'alpha': 10, 'n_estimators': 10}. Best is trial 0 with value: 0.7547842624509687.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:45,253]\u001b[0m Trial 1 finished with value: 0.7102103886841793 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 0 with value: 0.7547842624509687.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:46,377]\u001b[0m Trial 2 finished with value: 0.7677404017591822 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 100, 'n_estimators': 100}. Best is trial 2 with value: 0.7677404017591822.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:46,618]\u001b[0m Trial 3 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 8, 'alpha': 100, 'n_estimators': 10}. Best is trial 2 with value: 0.7677404017591822.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:47,998]\u001b[0m Trial 4 finished with value: 0.7734458576013312 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:48,243]\u001b[0m Trial 5 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.001, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:48,549]\u001b[0m Trial 6 finished with value: 0.7257815285867111 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 8, 'alpha': 100, 'n_estimators': 10}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:49,407]\u001b[0m Trial 7 finished with value: 0.6938072031380007 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 100, 'n_estimators': 100}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:51,936]\u001b[0m Trial 8 finished with value: 0.7248306192796862 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 10, 'alpha': 100, 'n_estimators': 100}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:53,272]\u001b[0m Trial 9 finished with value: 0.7310115297753477 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:53,966]\u001b[0m Trial 10 finished with value: 0.7606085819564959 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:55,265]\u001b[0m Trial 11 finished with value: 0.7719006299774159 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 4 with value: 0.7734458576013312.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:57,481]\u001b[0m Trial 12 finished with value: 0.7757042672055152 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 12 with value: 0.7757042672055152.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:58,150]\u001b[0m Trial 13 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 12 with value: 0.7757042672055152.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:58,821]\u001b[0m Trial 14 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 12 with value: 0.7757042672055152.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:20:59,434]\u001b[0m Trial 15 finished with value: 0.7635801735409485 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 12 with value: 0.7757042672055152.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:00,371]\u001b[0m Trial 16 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 10, 'n_estimators': 50}. Best is trial 12 with value: 0.7757042672055152.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:01,883]\u001b[0m Trial 17 finished with value: 0.7595388089860929 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 12 with value: 0.7757042672055152.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:02,373]\u001b[0m Trial 18 finished with value: 0.7792701771068584 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 18 with value: 0.7792701771068584.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:03,253]\u001b[0m Trial 19 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 10, 'n_estimators': 100}. Best is trial 18 with value: 0.7792701771068584.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:03,731]\u001b[0m Trial 20 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:04,330]\u001b[0m Trial 21 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:04,842]\u001b[0m Trial 22 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:05,332]\u001b[0m Trial 23 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:05,817]\u001b[0m Trial 24 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:06,373]\u001b[0m Trial 25 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:06,909]\u001b[0m Trial 26 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:07,459]\u001b[0m Trial 27 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:07,944]\u001b[0m Trial 28 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:09,704]\u001b[0m Trial 29 finished with value: 0.775466539878759 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:10,191]\u001b[0m Trial 30 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:10,937]\u001b[0m Trial 31 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:11,735]\u001b[0m Trial 32 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:12,668]\u001b[0m Trial 33 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:12,924]\u001b[0m Trial 34 finished with value: 0.6959467490788066 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:13,589]\u001b[0m Trial 35 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:14,095]\u001b[0m Trial 36 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:14,412]\u001b[0m Trial 37 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 8, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:14,915]\u001b[0m Trial 38 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:15,140]\u001b[0m Trial 39 finished with value: 0.7423035777962677 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 100, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:15,630]\u001b[0m Trial 40 finished with value: 0.6657553785807678 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:16,097]\u001b[0m Trial 41 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:16,608]\u001b[0m Trial 42 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:17,077]\u001b[0m Trial 43 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:17,569]\u001b[0m Trial 44 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:18,033]\u001b[0m Trial 45 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:18,191]\u001b[0m Trial 46 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:18,685]\u001b[0m Trial 47 finished with value: 0.6133365030310234 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:19,304]\u001b[0m Trial 48 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:20,546]\u001b[0m Trial 49 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:21,979]\u001b[0m Trial 50 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:22,465]\u001b[0m Trial 51 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:22,940]\u001b[0m Trial 52 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:23,411]\u001b[0m Trial 53 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:23,885]\u001b[0m Trial 54 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:24,756]\u001b[0m Trial 55 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:25,232]\u001b[0m Trial 56 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:25,616]\u001b[0m Trial 57 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:26,250]\u001b[0m Trial 58 finished with value: 0.7745156305717342 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:26,740]\u001b[0m Trial 59 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:27,133]\u001b[0m Trial 60 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.001, 'max_depth': 10, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:27,644]\u001b[0m Trial 61 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:28,602]\u001b[0m Trial 62 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:29,352]\u001b[0m Trial 63 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:29,880]\u001b[0m Trial 64 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:30,351]\u001b[0m Trial 65 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:32,099]\u001b[0m Trial 66 finished with value: 0.766432901462023 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 10, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:32,618]\u001b[0m Trial 67 finished with value: 0.7566860810650184 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:33,095]\u001b[0m Trial 68 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:33,865]\u001b[0m Trial 69 finished with value: 0.7677404017591822 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:34,298]\u001b[0m Trial 70 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:34,921]\u001b[0m Trial 71 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:35,519]\u001b[0m Trial 72 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:36,064]\u001b[0m Trial 73 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:36,549]\u001b[0m Trial 74 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:37,055]\u001b[0m Trial 75 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:37,212]\u001b[0m Trial 76 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:39,030]\u001b[0m Trial 77 finished with value: 0.6829906097705931 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:39,520]\u001b[0m Trial 78 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:42,155]\u001b[0m Trial 79 finished with value: 0.7749910852252466 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:42,629]\u001b[0m Trial 80 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:43,220]\u001b[0m Trial 81 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:43,990]\u001b[0m Trial 82 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:44,957]\u001b[0m Trial 83 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:46,035]\u001b[0m Trial 84 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:46,553]\u001b[0m Trial 85 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:47,208]\u001b[0m Trial 86 finished with value: 0.7779626768096993 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:47,742]\u001b[0m Trial 87 finished with value: 0.7678592654225603 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:47,905]\u001b[0m Trial 88 finished with value: 0.7526447165101628 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:48,530]\u001b[0m Trial 89 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:49,006]\u001b[0m Trial 90 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:49,448]\u001b[0m Trial 91 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:50,021]\u001b[0m Trial 92 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:50,455]\u001b[0m Trial 93 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:51,136]\u001b[0m Trial 94 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:51,776]\u001b[0m Trial 95 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:53,737]\u001b[0m Trial 96 finished with value: 0.7595388089860929 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:54,519]\u001b[0m Trial 97 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:54,982]\u001b[0m Trial 98 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:56,200]\u001b[0m Trial 99 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:56,653]\u001b[0m Trial 100 finished with value: 0.7399263045287056 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:57,106]\u001b[0m Trial 101 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:57,536]\u001b[0m Trial 102 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:57,978]\u001b[0m Trial 103 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:58,422]\u001b[0m Trial 104 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:58,893]\u001b[0m Trial 105 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:59,576]\u001b[0m Trial 106 finished with value: 0.7677404017591822 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:21:59,795]\u001b[0m Trial 107 finished with value: 0.7683347200760727 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:00,673]\u001b[0m Trial 108 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:01,229]\u001b[0m Trial 109 finished with value: 0.6375846903601569 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:01,884]\u001b[0m Trial 110 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:02,388]\u001b[0m Trial 111 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:03,031]\u001b[0m Trial 112 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:03,671]\u001b[0m Trial 113 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:04,141]\u001b[0m Trial 114 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:04,597]\u001b[0m Trial 115 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:08,205]\u001b[0m Trial 116 finished with value: 0.7604897182931178 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:08,695]\u001b[0m Trial 117 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:09,222]\u001b[0m Trial 118 finished with value: 0.7566860810650184 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:10,323]\u001b[0m Trial 119 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:10,802]\u001b[0m Trial 120 finished with value: 0.7640556281944609 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:11,290]\u001b[0m Trial 121 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:11,779]\u001b[0m Trial 122 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:12,373]\u001b[0m Trial 123 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:12,782]\u001b[0m Trial 124 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:13,249]\u001b[0m Trial 125 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:13,399]\u001b[0m Trial 126 finished with value: 0.7683347200760727 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:14,058]\u001b[0m Trial 127 finished with value: 0.7677404017591822 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:14,631]\u001b[0m Trial 128 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:15,297]\u001b[0m Trial 129 finished with value: 0.7773683584928087 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:15,955]\u001b[0m Trial 130 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:17,063]\u001b[0m Trial 131 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:17,638]\u001b[0m Trial 132 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:18,161]\u001b[0m Trial 133 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:18,714]\u001b[0m Trial 134 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:19,292]\u001b[0m Trial 135 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:19,895]\u001b[0m Trial 136 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:20,423]\u001b[0m Trial 137 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:23,148]\u001b[0m Trial 138 finished with value: 0.7604897182931178 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:23,682]\u001b[0m Trial 139 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:24,189]\u001b[0m Trial 140 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:24,657]\u001b[0m Trial 141 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:25,141]\u001b[0m Trial 142 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:25,619]\u001b[0m Trial 143 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:26,136]\u001b[0m Trial 144 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:26,621]\u001b[0m Trial 145 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:27,095]\u001b[0m Trial 146 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:27,569]\u001b[0m Trial 147 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:27,732]\u001b[0m Trial 148 finished with value: 0.7683347200760727 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:28,236]\u001b[0m Trial 149 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:28,737]\u001b[0m Trial 150 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:29,220]\u001b[0m Trial 151 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:29,693]\u001b[0m Trial 152 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:30,168]\u001b[0m Trial 153 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:30,674]\u001b[0m Trial 154 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:31,402]\u001b[0m Trial 155 finished with value: 0.7677404017591822 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:32,169]\u001b[0m Trial 156 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:33,248]\u001b[0m Trial 157 finished with value: 0.7773683584928087 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:33,763]\u001b[0m Trial 158 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:34,297]\u001b[0m Trial 159 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:35,437]\u001b[0m Trial 160 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:35,961]\u001b[0m Trial 161 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:36,488]\u001b[0m Trial 162 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:37,191]\u001b[0m Trial 163 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:37,824]\u001b[0m Trial 164 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:38,420]\u001b[0m Trial 165 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:39,216]\u001b[0m Trial 166 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:41,733]\u001b[0m Trial 167 finished with value: 0.7582313086889338 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:42,202]\u001b[0m Trial 168 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:44,049]\u001b[0m Trial 169 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:45,023]\u001b[0m Trial 170 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:45,643]\u001b[0m Trial 171 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:46,351]\u001b[0m Trial 172 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:46,925]\u001b[0m Trial 173 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:47,394]\u001b[0m Trial 174 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:47,889]\u001b[0m Trial 175 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:48,188]\u001b[0m Trial 176 finished with value: 0.7683347200760727 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:48,953]\u001b[0m Trial 177 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:49,965]\u001b[0m Trial 178 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:50,439]\u001b[0m Trial 179 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:51,089]\u001b[0m Trial 180 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:51,511]\u001b[0m Trial 181 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:51,948]\u001b[0m Trial 182 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:52,390]\u001b[0m Trial 183 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:52,879]\u001b[0m Trial 184 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:53,404]\u001b[0m Trial 185 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:53,887]\u001b[0m Trial 186 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:54,332]\u001b[0m Trial 187 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:55,129]\u001b[0m Trial 188 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:55,569]\u001b[0m Trial 189 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:56,004]\u001b[0m Trial 190 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:56,421]\u001b[0m Trial 191 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:56,885]\u001b[0m Trial 192 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:57,350]\u001b[0m Trial 193 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:57,799]\u001b[0m Trial 194 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:58,239]\u001b[0m Trial 195 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:58,717]\u001b[0m Trial 196 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:59,169]\u001b[0m Trial 197 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:22:59,662]\u001b[0m Trial 198 finished with value: 0.7703554023535005 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 100, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:23:00,111]\u001b[0m Trial 199 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 20 with value: 0.7796267680969927.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Accuracy : 0.7796267680969927\n",
      "Best Train Accuracy: 0.8056521351520014\n",
      "Best Parameters    : {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -------------------------\n",
    "# Prepare data ONCE\n",
    "# -------------------------\n",
    "y = df_encoded[\"Approved_Flag\"]\n",
    "X = df_encoded.drop(columns=[\"Approved_Flag\"])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_enc\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optuna objective\n",
    "# -------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softmax\",\n",
    "        \"num_class\": 4,\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 0.9, step=0.2),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.001, 0.01, 0.1, 1.0]),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", [3, 5, 8, 10]),\n",
    "        \"reg_alpha\": trial.suggest_categorical(\"alpha\", [1, 10, 100]),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10, 50, 100]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"eval_metric\": \"mlogloss\"\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds  = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    test_acc  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "    # store train accuracy for the best trial\n",
    "    trial.set_user_attr(\"train_accuracy\", train_acc)\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "# -------------------------\n",
    "# Run optimization\n",
    "# -------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=False)\n",
    "\n",
    "# -------------------------\n",
    "# Print ONLY best result\n",
    "# -------------------------\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"Best Test Accuracy :\", best_trial.value)\n",
    "print(\"Best Train Accuracy:\", best_trial.user_attrs[\"train_accuracy\"])\n",
    "print(\"Best Parameters    :\", best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81248b35-77ab-451c-a5ca-6cf4a1d1bd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>Unsecured_TL</th>\n",
       "      <th>Other_TL</th>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <th>Age_Newest_TL</th>\n",
       "      <th>time_since_recent_payment</th>\n",
       "      <th>max_recent_level_of_deliq</th>\n",
       "      <th>num_deliq_6_12mts</th>\n",
       "      <th>num_times_60p_dpd</th>\n",
       "      <th>num_std_12mts</th>\n",
       "      <th>num_sub</th>\n",
       "      <th>num_sub_6mts</th>\n",
       "      <th>num_sub_12mts</th>\n",
       "      <th>num_dbt</th>\n",
       "      <th>num_dbt_12mts</th>\n",
       "      <th>num_lss</th>\n",
       "      <th>recent_level_of_deliq</th>\n",
       "      <th>CC_enq_L12m</th>\n",
       "      <th>PL_enq_L12m</th>\n",
       "      <th>time_since_recent_enq</th>\n",
       "      <th>enq_L3m</th>\n",
       "      <th>NETMONTHLYINCOME</th>\n",
       "      <th>Time_With_Curr_Empr</th>\n",
       "      <th>CC_Flag</th>\n",
       "      <th>PL_Flag</th>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <th>HL_Flag</th>\n",
       "      <th>GL_Flag</th>\n",
       "      <th>EDUCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.00000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>4.206400e+04</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.097783</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>0.160365</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>0.145921</td>\n",
       "      <td>0.076241</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>2.921334</td>\n",
       "      <td>2.341646</td>\n",
       "      <td>1.116489</td>\n",
       "      <td>46.498074</td>\n",
       "      <td>13.970046</td>\n",
       "      <td>218.601607</td>\n",
       "      <td>14.314758</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>0.438879</td>\n",
       "      <td>3.279978</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.02451</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>11.803918</td>\n",
       "      <td>0.268924</td>\n",
       "      <td>0.779194</td>\n",
       "      <td>264.854507</td>\n",
       "      <td>1.230458</td>\n",
       "      <td>2.692990e+04</td>\n",
       "      <td>110.345783</td>\n",
       "      <td>0.102962</td>\n",
       "      <td>0.193063</td>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.064186</td>\n",
       "      <td>0.252235</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>2.313689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.278043</td>\n",
       "      <td>0.210957</td>\n",
       "      <td>1.537208</td>\n",
       "      <td>0.258831</td>\n",
       "      <td>1.106442</td>\n",
       "      <td>0.549314</td>\n",
       "      <td>0.358582</td>\n",
       "      <td>0.916368</td>\n",
       "      <td>6.379764</td>\n",
       "      <td>3.405397</td>\n",
       "      <td>2.486801</td>\n",
       "      <td>42.109230</td>\n",
       "      <td>18.835191</td>\n",
       "      <td>422.282417</td>\n",
       "      <td>54.056303</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>7.566312</td>\n",
       "      <td>0.799989</td>\n",
       "      <td>0.081704</td>\n",
       "      <td>0.220786</td>\n",
       "      <td>0.62189</td>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.573762</td>\n",
       "      <td>46.422091</td>\n",
       "      <td>1.019459</td>\n",
       "      <td>1.802092</td>\n",
       "      <td>466.585002</td>\n",
       "      <td>2.069461</td>\n",
       "      <td>2.084300e+04</td>\n",
       "      <td>75.629967</td>\n",
       "      <td>0.303913</td>\n",
       "      <td>0.394707</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.231042</td>\n",
       "      <td>0.871070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000e+04</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000e+04</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.100000e+04</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>6065.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4768.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pct_tl_open_L6M  pct_tl_closed_L6M  Tot_TL_closed_L12M  \\\n",
       "count     42064.000000       42064.000000        42064.000000   \n",
       "mean          0.179032           0.097783            0.825504   \n",
       "std           0.278043           0.210957            1.537208   \n",
       "min           0.000000           0.000000            0.000000   \n",
       "25%           0.000000           0.000000            0.000000   \n",
       "50%           0.000000           0.000000            0.000000   \n",
       "75%           0.333000           0.100000            1.000000   \n",
       "max           1.000000           1.000000           33.000000   \n",
       "\n",
       "       pct_tl_closed_L12M  Tot_Missed_Pmnt         CC_TL       Home_TL  \\\n",
       "count        42064.000000     42064.000000  42064.000000  42064.000000   \n",
       "mean             0.160365         0.525746      0.145921      0.076241   \n",
       "std              0.258831         1.106442      0.549314      0.358582   \n",
       "min              0.000000         0.000000      0.000000      0.000000   \n",
       "25%              0.000000         0.000000      0.000000      0.000000   \n",
       "50%              0.000000         0.000000      0.000000      0.000000   \n",
       "75%              0.250000         1.000000      0.000000      0.000000   \n",
       "max              1.000000        34.000000     27.000000     10.000000   \n",
       "\n",
       "              PL_TL    Secured_TL  Unsecured_TL      Other_TL  Age_Oldest_TL  \\\n",
       "count  42064.000000  42064.000000  42064.000000  42064.000000   42064.000000   \n",
       "mean       0.328000      2.921334      2.341646      1.116489      46.498074   \n",
       "std        0.916368      6.379764      3.405397      2.486801      42.109230   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      14.000000   \n",
       "50%        0.000000      1.000000      1.000000      0.000000      34.000000   \n",
       "75%        0.000000      3.000000      3.000000      1.000000      65.000000   \n",
       "max       29.000000    235.000000     55.000000     80.000000     385.000000   \n",
       "\n",
       "       Age_Newest_TL  time_since_recent_payment  max_recent_level_of_deliq  \\\n",
       "count   42064.000000               42064.000000               42064.000000   \n",
       "mean       13.970046                 218.601607                  14.314758   \n",
       "std        18.835191                 422.282417                  54.056303   \n",
       "min         0.000000                   2.000000                   0.000000   \n",
       "25%         4.000000                  51.000000                   0.000000   \n",
       "50%         7.000000                  71.000000                   0.000000   \n",
       "75%        16.000000                 146.000000                  15.000000   \n",
       "max       359.000000                6065.000000                 900.000000   \n",
       "\n",
       "       num_deliq_6_12mts  num_times_60p_dpd  num_std_12mts       num_sub  \\\n",
       "count       42064.000000       42064.000000   42064.000000  42064.000000   \n",
       "mean            0.336963           0.438879       3.279978      0.063831   \n",
       "std             1.097356           2.148400       7.566312      0.799989   \n",
       "min             0.000000           0.000000       0.000000      0.000000   \n",
       "25%             0.000000           0.000000       0.000000      0.000000   \n",
       "50%             0.000000           0.000000       0.000000      0.000000   \n",
       "75%             0.000000           0.000000       3.000000      0.000000   \n",
       "max            20.000000          52.000000     122.000000     41.000000   \n",
       "\n",
       "       num_sub_6mts  num_sub_12mts      num_dbt  num_dbt_12mts       num_lss  \\\n",
       "count  42064.000000   42064.000000  42064.00000   42064.000000  42064.000000   \n",
       "mean       0.002211       0.009224      0.02451       0.004279      0.016713   \n",
       "std        0.081704       0.220786      0.62189       0.184461      0.573762   \n",
       "min        0.000000       0.000000      0.00000       0.000000      0.000000   \n",
       "25%        0.000000       0.000000      0.00000       0.000000      0.000000   \n",
       "50%        0.000000       0.000000      0.00000       0.000000      0.000000   \n",
       "75%        0.000000       0.000000      0.00000       0.000000      0.000000   \n",
       "max        5.000000      12.000000     35.00000      12.000000     72.000000   \n",
       "\n",
       "       recent_level_of_deliq   CC_enq_L12m   PL_enq_L12m  \\\n",
       "count           42064.000000  42064.000000  42064.000000   \n",
       "mean               11.803918      0.268924      0.779194   \n",
       "std                46.422091      1.019459      1.802092   \n",
       "min                 0.000000      0.000000      0.000000   \n",
       "25%                 0.000000      0.000000      0.000000   \n",
       "50%                 0.000000      0.000000      0.000000   \n",
       "75%                11.000000      0.000000      1.000000   \n",
       "max               900.000000     24.000000     44.000000   \n",
       "\n",
       "       time_since_recent_enq       enq_L3m  NETMONTHLYINCOME  \\\n",
       "count           42064.000000  42064.000000      4.206400e+04   \n",
       "mean              264.854507      1.230458      2.692990e+04   \n",
       "std               466.585002      2.069461      2.084300e+04   \n",
       "min                 0.000000      0.000000      0.000000e+00   \n",
       "25%                 9.000000      0.000000      1.800000e+04   \n",
       "50%                79.000000      1.000000      2.400000e+04   \n",
       "75%               302.000000      2.000000      3.100000e+04   \n",
       "max              4768.000000     42.000000      2.500000e+06   \n",
       "\n",
       "       Time_With_Curr_Empr       CC_Flag       PL_Flag  \\\n",
       "count         42064.000000  42064.000000  42064.000000   \n",
       "mean            110.345783      0.102962      0.193063   \n",
       "std              75.629967      0.303913      0.394707   \n",
       "min               0.000000      0.000000      0.000000   \n",
       "25%              61.000000      0.000000      0.000000   \n",
       "50%              92.000000      0.000000      0.000000   \n",
       "75%             131.000000      0.000000      0.000000   \n",
       "max            1020.000000      1.000000      1.000000   \n",
       "\n",
       "       pct_PL_enq_L6m_of_ever  pct_CC_enq_L6m_of_ever       HL_Flag  \\\n",
       "count            42064.000000            42064.000000  42064.000000   \n",
       "mean                 0.195497                0.064186      0.252235   \n",
       "std                  0.367414                0.225989      0.434300   \n",
       "min                  0.000000                0.000000      0.000000   \n",
       "25%                  0.000000                0.000000      0.000000   \n",
       "50%                  0.000000                0.000000      0.000000   \n",
       "75%                  0.000000                0.000000      1.000000   \n",
       "max                  1.000000                1.000000      1.000000   \n",
       "\n",
       "            GL_Flag     EDUCATION  \n",
       "count  42064.000000  42064.000000  \n",
       "mean       0.056580      2.313689  \n",
       "std        0.231042      0.871070  \n",
       "min        0.000000      1.000000  \n",
       "25%        0.000000      2.000000  \n",
       "50%        0.000000      2.000000  \n",
       "75%        0.000000      3.000000  \n",
       "max        1.000000      4.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3b7639e-d87a-4508-9e08-de8826880011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaler \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_be_scaled = ['Age_Oldest_TL','Age_Newest_TL','time_since_recent_payment',\n",
    "'max_recent_level_of_deliq','recent_level_of_deliq',\n",
    "'time_since_recent_enq','NETMONTHLYINCOME','Time_With_Curr_Empr']\n",
    "\n",
    "for i in columns_to_be_scaled:\n",
    "    column_data = df_encoded[i].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_column = scaler.fit_transform(column_data)\n",
    "    df_encoded[i] = scaled_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbbe7a46-9ae5-4332-93b0-e20acdbcbdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.7726138119576845\n",
      "\n",
      "Class p1\n",
      "Precision = 0.8232804232804233\n",
      "Recall = 0.7672583826429981\n",
      "F1_score = 0.7942827973455845\n",
      "\n",
      "Class p2\n",
      "Precision = 0.8261887608069164\n",
      "Recall = 0.9092170465807731\n",
      "F1_score = 0.8657167122770596\n",
      "\n",
      "Class p3\n",
      "Precision = 0.44532130777903045\n",
      "Recall = 0.2981132075471698\n",
      "F1_score = 0.35714285714285715\n",
      "\n",
      "Class p4\n",
      "Precision = 0.7191448007774538\n",
      "Recall = 0.7191448007774538\n",
      "F1_score = 0.7191448007774538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e11298a9-9608-4b04-88ae-da1d20867505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-26 23:33:09,613]\u001b[0m A new study created in memory with name: no-name-d709662a-fc5d-495c-9cbe-465224c68fa5\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:14,768]\u001b[0m Trial 0 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 10, 'alpha': 1, 'n_estimators': 100}. Best is trial 0 with value: 0.605016046594556.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:14,934]\u001b[0m Trial 1 finished with value: 0.6900035659099013 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 10}. Best is trial 1 with value: 0.6900035659099013.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:15,283]\u001b[0m Trial 2 finished with value: 0.7719006299774159 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 8, 'alpha': 1, 'n_estimators': 10}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:15,815]\u001b[0m Trial 3 finished with value: 0.7566860810650184 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:16,097]\u001b[0m Trial 4 finished with value: 0.6971353857125877 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'alpha': 100, 'n_estimators': 10}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:17,020]\u001b[0m Trial 5 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 0.001, 'max_depth': 8, 'alpha': 100, 'n_estimators': 100}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:18,740]\u001b[0m Trial 6 finished with value: 0.7688101747295851 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:20,112]\u001b[0m Trial 7 finished with value: 0.74717698799477 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:21,272]\u001b[0m Trial 8 finished with value: 0.7168667538333532 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 10, 'n_estimators': 100}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:21,811]\u001b[0m Trial 9 finished with value: 0.6657553785807678 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:22,099]\u001b[0m Trial 10 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 8, 'alpha': 10, 'n_estimators': 10}. Best is trial 2 with value: 0.7719006299774159.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:22,302]\u001b[0m Trial 11 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:22,502]\u001b[0m Trial 12 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:22,705]\u001b[0m Trial 13 finished with value: 0.7701176750267443 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:22,913]\u001b[0m Trial 14 finished with value: 0.7745156305717342 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:23,117]\u001b[0m Trial 15 finished with value: 0.7579935813621775 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:23,329]\u001b[0m Trial 16 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:23,534]\u001b[0m Trial 17 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:23,752]\u001b[0m Trial 18 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 5, 'alpha': 100, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:24,480]\u001b[0m Trial 19 finished with value: 0.6957090217520504 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:24,872]\u001b[0m Trial 20 finished with value: 0.745988351360989 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:25,078]\u001b[0m Trial 21 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:25,276]\u001b[0m Trial 22 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:25,483]\u001b[0m Trial 23 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:25,691]\u001b[0m Trial 24 finished with value: 0.7745156305717342 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:25,896]\u001b[0m Trial 25 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:26,092]\u001b[0m Trial 26 finished with value: 0.7745156305717342 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:26,289]\u001b[0m Trial 27 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.001, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:27,857]\u001b[0m Trial 28 finished with value: 0.6392487816474504 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.01, 'max_depth': 10, 'alpha': 100, 'n_estimators': 100}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:31,874]\u001b[0m Trial 29 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'alpha': 10, 'n_estimators': 100}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:32,801]\u001b[0m Trial 30 finished with value: 0.7716629026506597 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:33,050]\u001b[0m Trial 31 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:33,256]\u001b[0m Trial 32 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:33,464]\u001b[0m Trial 33 finished with value: 0.7748722215618685 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:33,620]\u001b[0m Trial 34 finished with value: 0.7663140377986449 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:33,906]\u001b[0m Trial 35 finished with value: 0.7444431237370736 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:34,144]\u001b[0m Trial 36 finished with value: 0.7648876738381077 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 100, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:34,347]\u001b[0m Trial 37 finished with value: 0.7444431237370736 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 11 with value: 0.7748722215618685.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:34,837]\u001b[0m Trial 38 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 38 with value: 0.7774872221561868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:35,218]\u001b[0m Trial 39 finished with value: 0.7651254011648639 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 38 with value: 0.7774872221561868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:35,726]\u001b[0m Trial 40 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 38 with value: 0.7774872221561868.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:36,230]\u001b[0m Trial 41 finished with value: 0.7779626768096993 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 41 with value: 0.7779626768096993.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:36,852]\u001b[0m Trial 42 finished with value: 0.7779626768096993 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 41 with value: 0.7779626768096993.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:37,453]\u001b[0m Trial 43 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 41 with value: 0.7779626768096993.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:37,941]\u001b[0m Trial 44 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:38,440]\u001b[0m Trial 45 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:38,953]\u001b[0m Trial 46 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:39,560]\u001b[0m Trial 47 finished with value: 0.7773683584928087 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:40,235]\u001b[0m Trial 48 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:40,931]\u001b[0m Trial 49 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:41,447]\u001b[0m Trial 50 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:41,977]\u001b[0m Trial 51 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:42,517]\u001b[0m Trial 52 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:42,995]\u001b[0m Trial 53 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:43,466]\u001b[0m Trial 54 finished with value: 0.7774872221561868 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:44,310]\u001b[0m Trial 55 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:45,301]\u001b[0m Trial 56 finished with value: 0.6375846903601569 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:45,800]\u001b[0m Trial 57 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:46,301]\u001b[0m Trial 58 finished with value: 0.7383810769047902 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:47,405]\u001b[0m Trial 59 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:47,881]\u001b[0m Trial 60 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:48,358]\u001b[0m Trial 61 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:48,839]\u001b[0m Trial 62 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:49,322]\u001b[0m Trial 63 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:49,864]\u001b[0m Trial 64 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:50,787]\u001b[0m Trial 65 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:51,402]\u001b[0m Trial 66 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:52,584]\u001b[0m Trial 67 finished with value: 0.767502674432426 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:53,068]\u001b[0m Trial 68 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:54,326]\u001b[0m Trial 69 finished with value: 0.6809699274931653 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:54,985]\u001b[0m Trial 70 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:55,452]\u001b[0m Trial 71 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:55,932]\u001b[0m Trial 72 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:56,406]\u001b[0m Trial 73 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:56,896]\u001b[0m Trial 74 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:57,414]\u001b[0m Trial 75 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:58,972]\u001b[0m Trial 76 finished with value: 0.7595388089860929 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:33:59,485]\u001b[0m Trial 77 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:00,259]\u001b[0m Trial 78 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:01,141]\u001b[0m Trial 79 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:02,071]\u001b[0m Trial 80 finished with value: 0.7705931296802567 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:02,570]\u001b[0m Trial 81 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:03,071]\u001b[0m Trial 82 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:03,576]\u001b[0m Trial 83 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:04,128]\u001b[0m Trial 84 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:05,343]\u001b[0m Trial 85 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:05,855]\u001b[0m Trial 86 finished with value: 0.7792701771068584 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:06,342]\u001b[0m Trial 87 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:06,894]\u001b[0m Trial 88 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:07,416]\u001b[0m Trial 89 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:09,288]\u001b[0m Trial 90 finished with value: 0.6829906097705931 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:09,794]\u001b[0m Trial 91 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:10,339]\u001b[0m Trial 92 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:10,806]\u001b[0m Trial 93 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:11,298]\u001b[0m Trial 94 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:11,774]\u001b[0m Trial 95 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:12,266]\u001b[0m Trial 96 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:12,760]\u001b[0m Trial 97 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:13,982]\u001b[0m Trial 98 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:14,534]\u001b[0m Trial 99 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:16,038]\u001b[0m Trial 100 finished with value: 0.7699988113633662 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:17,038]\u001b[0m Trial 101 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:17,809]\u001b[0m Trial 102 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:18,306]\u001b[0m Trial 103 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:18,794]\u001b[0m Trial 104 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:19,274]\u001b[0m Trial 105 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:19,683]\u001b[0m Trial 106 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:20,198]\u001b[0m Trial 107 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:20,681]\u001b[0m Trial 108 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:22,339]\u001b[0m Trial 109 finished with value: 0.6329490074884108 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.01, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:22,886]\u001b[0m Trial 110 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:23,386]\u001b[0m Trial 111 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:23,864]\u001b[0m Trial 112 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:24,342]\u001b[0m Trial 113 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:24,872]\u001b[0m Trial 114 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:25,349]\u001b[0m Trial 115 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:26,207]\u001b[0m Trial 116 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:26,701]\u001b[0m Trial 117 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:27,178]\u001b[0m Trial 118 finished with value: 0.7640556281944609 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:27,661]\u001b[0m Trial 119 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:28,912]\u001b[0m Trial 120 finished with value: 0.775466539878759 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:29,514]\u001b[0m Trial 121 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:30,047]\u001b[0m Trial 122 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:30,545]\u001b[0m Trial 123 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:31,029]\u001b[0m Trial 124 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:31,498]\u001b[0m Trial 125 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:32,118]\u001b[0m Trial 126 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:33,218]\u001b[0m Trial 127 finished with value: 0.7773683584928087 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:33,761]\u001b[0m Trial 128 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:34,365]\u001b[0m Trial 129 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:36,020]\u001b[0m Trial 130 finished with value: 0.7595388089860929 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:36,556]\u001b[0m Trial 131 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:37,163]\u001b[0m Trial 132 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:37,688]\u001b[0m Trial 133 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:38,163]\u001b[0m Trial 134 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:38,702]\u001b[0m Trial 135 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:39,493]\u001b[0m Trial 136 finished with value: 0.6822774277903245 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:40,089]\u001b[0m Trial 137 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:40,662]\u001b[0m Trial 138 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:41,383]\u001b[0m Trial 139 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:41,895]\u001b[0m Trial 140 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:42,534]\u001b[0m Trial 141 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:43,126]\u001b[0m Trial 142 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:43,787]\u001b[0m Trial 143 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:44,395]\u001b[0m Trial 144 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:44,882]\u001b[0m Trial 145 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:45,392]\u001b[0m Trial 146 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:46,550]\u001b[0m Trial 147 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:47,113]\u001b[0m Trial 148 finished with value: 0.7773683584928087 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:47,670]\u001b[0m Trial 149 finished with value: 0.7399263045287056 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:48,470]\u001b[0m Trial 150 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:49,508]\u001b[0m Trial 151 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:49,980]\u001b[0m Trial 152 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:50,455]\u001b[0m Trial 153 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:50,912]\u001b[0m Trial 154 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:51,433]\u001b[0m Trial 155 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:51,947]\u001b[0m Trial 156 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:52,496]\u001b[0m Trial 157 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:54,099]\u001b[0m Trial 158 finished with value: 0.7595388089860929 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:55,099]\u001b[0m Trial 159 finished with value: 0.7752288125520028 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:55,518]\u001b[0m Trial 160 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:56,067]\u001b[0m Trial 161 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:56,523]\u001b[0m Trial 162 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:56,987]\u001b[0m Trial 163 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:57,436]\u001b[0m Trial 164 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:57,944]\u001b[0m Trial 165 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:58,149]\u001b[0m Trial 166 finished with value: 0.7701176750267443 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 10}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:58,708]\u001b[0m Trial 167 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:59,181]\u001b[0m Trial 168 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:34:59,634]\u001b[0m Trial 169 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:00,159]\u001b[0m Trial 170 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:00,672]\u001b[0m Trial 171 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:01,095]\u001b[0m Trial 172 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:01,518]\u001b[0m Trial 173 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:02,152]\u001b[0m Trial 174 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:02,701]\u001b[0m Trial 175 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:04,534]\u001b[0m Trial 176 finished with value: 0.7550219897777249 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 8, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:05,523]\u001b[0m Trial 177 finished with value: 0.7773683584928087 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:06,025]\u001b[0m Trial 178 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:06,371]\u001b[0m Trial 179 finished with value: 0.7657197194817544 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:06,806]\u001b[0m Trial 180 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:07,234]\u001b[0m Trial 181 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:07,718]\u001b[0m Trial 182 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:08,273]\u001b[0m Trial 183 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:08,759]\u001b[0m Trial 184 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:09,201]\u001b[0m Trial 185 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:09,816]\u001b[0m Trial 186 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:10,517]\u001b[0m Trial 187 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:12,801]\u001b[0m Trial 188 finished with value: 0.7604897182931178 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 10, 'alpha': 1, 'n_estimators': 100}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:13,237]\u001b[0m Trial 189 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:13,800]\u001b[0m Trial 190 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:14,342]\u001b[0m Trial 191 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:14,963]\u001b[0m Trial 192 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:15,404]\u001b[0m Trial 193 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:16,062]\u001b[0m Trial 194 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:16,632]\u001b[0m Trial 195 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:17,276]\u001b[0m Trial 196 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:17,462]\u001b[0m Trial 197 finished with value: 0.7683347200760727 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:18,168]\u001b[0m Trial 198 finished with value: 0.7796267680969927 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n",
      "\u001b[32m[I 2026-01-26 23:35:19,035]\u001b[0m Trial 199 finished with value: 0.7677404017591822 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 44 with value: 0.7796267680969927.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Accuracy : 0.7796267680969927\n",
      "Best Train Accuracy: 0.8056521351520014\n",
      "Best Parameters    : {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "y = df_encoded[\"Approved_Flag\"]\n",
    "X = df_encoded.drop(columns=[\"Approved_Flag\"])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_enc\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optuna objective\n",
    "# -------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softmax\",\n",
    "        \"num_class\": 4,\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 0.9, step=0.2),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.001, 0.01, 0.1, 1.0]),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", [3, 5, 8, 10]),\n",
    "        \"reg_alpha\": trial.suggest_categorical(\"alpha\", [1, 10, 100]),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10, 50, 100]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"eval_metric\": \"mlogloss\"\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds  = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    test_acc  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "    # store train accuracy for the best trial\n",
    "    trial.set_user_attr(\"train_accuracy\", train_acc)\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "# -------------------------\n",
    "# Run optimization\n",
    "# -------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=False)\n",
    "\n",
    "# -------------------------\n",
    "# Print ONLY best result\n",
    "# -------------------------\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"Best Test Accuracy :\", best_trial.value)\n",
    "print(\"Best Train Accuracy:\", best_trial.user_attrs[\"train_accuracy\"])\n",
    "print(\"Best Parameters    :\", best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e30bc-3f87-457d-9e81-74283e21ea27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29e0dc-14d1-450c-8a96-8bcff5935edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6439c-670c-46a2-b2eb-e384befcd61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e46c0-a941-4848-9664-6d57243d0a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b04dac90-cdbf-4434-aa2a-671967e60daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 42)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for unseen data\n",
    "\n",
    "un = pd.read_excel('/Users/shraddhagupta/Downloads/Unseen_Dataset.xlsx')\n",
    "un.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04f70cf4-a193-4020-8c1e-91c6ce501ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 50 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               100 non-null    float64\n",
      " 1   pct_tl_closed_L6M             100 non-null    float64\n",
      " 2   Tot_TL_closed_L12M            100 non-null    int64  \n",
      " 3   pct_tl_closed_L12M            100 non-null    float64\n",
      " 4   Tot_Missed_Pmnt               100 non-null    int64  \n",
      " 5   CC_TL                         100 non-null    int64  \n",
      " 6   Home_TL                       100 non-null    int64  \n",
      " 7   PL_TL                         100 non-null    int64  \n",
      " 8   Secured_TL                    100 non-null    int64  \n",
      " 9   Unsecured_TL                  100 non-null    int64  \n",
      " 10  Other_TL                      100 non-null    int64  \n",
      " 11  Age_Oldest_TL                 100 non-null    int64  \n",
      " 12  Age_Newest_TL                 100 non-null    int64  \n",
      " 13  time_since_recent_payment     100 non-null    int64  \n",
      " 14  max_recent_level_of_deliq     100 non-null    int64  \n",
      " 15  num_deliq_6_12mts             100 non-null    int64  \n",
      " 16  num_times_60p_dpd             100 non-null    int64  \n",
      " 17  num_std_12mts                 100 non-null    int64  \n",
      " 18  num_sub                       100 non-null    int64  \n",
      " 19  num_sub_6mts                  100 non-null    int64  \n",
      " 20  num_sub_12mts                 100 non-null    int64  \n",
      " 21  num_dbt                       100 non-null    int64  \n",
      " 22  num_dbt_12mts                 100 non-null    int64  \n",
      " 23  num_lss                       100 non-null    int64  \n",
      " 24  recent_level_of_deliq         100 non-null    int64  \n",
      " 25  CC_enq_L12m                   100 non-null    int64  \n",
      " 26  PL_enq_L12m                   100 non-null    int64  \n",
      " 27  time_since_recent_enq         100 non-null    int64  \n",
      " 28  enq_L3m                       100 non-null    int64  \n",
      " 29  NETMONTHLYINCOME              100 non-null    int64  \n",
      " 30  Time_With_Curr_Empr           100 non-null    int64  \n",
      " 31  CC_Flag                       100 non-null    int64  \n",
      " 32  PL_Flag                       100 non-null    int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        100 non-null    float64\n",
      " 34  pct_CC_enq_L6m_of_ever        100 non-null    float64\n",
      " 35  HL_Flag                       100 non-null    int64  \n",
      " 36  GL_Flag                       100 non-null    int64  \n",
      " 37  EDUCATION                     100 non-null    int64  \n",
      " 38  MARITALSTATUS_Single          100 non-null    bool   \n",
      " 39  GENDER_M                      100 non-null    bool   \n",
      " 40  last_prod_enq2_CC             100 non-null    bool   \n",
      " 41  last_prod_enq2_ConsumerLoan   100 non-null    bool   \n",
      " 42  last_prod_enq2_HL             100 non-null    bool   \n",
      " 43  last_prod_enq2_PL             100 non-null    bool   \n",
      " 44  last_prod_enq2_others         100 non-null    bool   \n",
      " 45  first_prod_enq2_CC            100 non-null    bool   \n",
      " 46  first_prod_enq2_ConsumerLoan  100 non-null    bool   \n",
      " 47  first_prod_enq2_HL            100 non-null    bool   \n",
      " 48  first_prod_enq2_PL            100 non-null    bool   \n",
      " 49  first_prod_enq2_others        100 non-null    bool   \n",
      "dtypes: bool(12), float64(5), int64(33)\n",
      "memory usage: 31.0 KB\n"
     ]
    }
   ],
   "source": [
    "# ordinal encoding for education\n",
    "\n",
    "un.loc[un['EDUCATION']=='SSC', ['EDUCATION']] = 1\n",
    "un.loc[un['EDUCATION']=='12TH', ['EDUCATION']] = 2\n",
    "un.loc[un['EDUCATION']=='UNDER GRADUATE', ['EDUCATION']] = 3\n",
    "un.loc[un['EDUCATION']=='GRADUATE', ['EDUCATION']] = 3\n",
    "un.loc[un['EDUCATION']=='POST-GRADUATE', ['EDUCATION']] = 4\n",
    "un.loc[un['EDUCATION']=='PROFESSIONAL', ['EDUCATION']] = 3\n",
    "un.loc[un['EDUCATION']=='OTHERS', ['EDUCATION']] = 1\n",
    "\n",
    "un['EDUCATION'] = un['EDUCATION'].astype(int)\n",
    "\n",
    "\n",
    "# one-hot encoding for other categorical columns\n",
    "\n",
    "df_unseen = pd.get_dummies(un, columns=['MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2'], drop_first=True)\n",
    "df_unseen.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f4ebdfc-65b4-4b89-8033-f28669e74d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=4, \n",
    "                         colsample_bytree=0.9, learning_rate=1,\n",
    "                         max_depth=3, alpha=1, n_estimators=50)\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(x_trian, y_train)\n",
    "\n",
    "y_pred_unseen = model.predict(df_unseen)\n",
    "\n",
    "df_unseen['Target'] = y_pred_unseen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e742d29-860c-4936-ae58-9f43916b1ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_v\n",
       "P1    74\n",
       "P2    20\n",
       "P3     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(y_pred_unseen)\n",
    "df_unseen['Target_v'] = y_pred\n",
    "\n",
    "df_unseen['Target_v'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cada4-902d-4120-ba0b-03d169f4fa70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf8f1d-e33c-4129-b7f2-004c0bced180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58034682-bbe1-41d9-ace1-ec36ace5f99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c2f93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#   'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#   'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
    "#   'max_depth'       : [3, 5, 8, 10],\n",
    "#   'alpha'           : [1, 10, 100],\n",
    "#   'n_estimators'    : [10,50,100]\n",
    "# }\n",
    "\n",
    "# index = 0\n",
    "\n",
    "# answers_grid = {\n",
    "#     'combination'       :[],\n",
    "#     'train_Accuracy'    :[],\n",
    "#     'test_Accuracy'     :[],\n",
    "#     'colsample_bytree'  :[],\n",
    "#     'learning_rate'     :[],\n",
    "#     'max_depth'         :[],\n",
    "#     'alpha'             :[],\n",
    "#     'n_estimators'      :[]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Loop through each combination of hyperparameters\n",
    "# for colsample_bytree in param_grid['colsample_bytree']:\n",
    "#   for learning_rate in param_grid['learning_rate']:\n",
    "#     for max_depth in param_grid['max_depth']:\n",
    "#       for alpha in param_grid['alpha']:\n",
    "#           for n_estimators in param_grid['n_estimators']:\n",
    "             \n",
    "#               index = index + 1\n",
    "             \n",
    "#               # Define and train the XGBoost model\n",
    "#               model = xgb.XGBClassifier(objective='multi:softmax',  \n",
    "#                                        num_class=4,\n",
    "#                                        colsample_bytree = colsample_bytree,\n",
    "#                                        learning_rate = learning_rate,\n",
    "#                                        max_depth = max_depth,\n",
    "#                                        alpha = alpha,\n",
    "#                                        n_estimators = n_estimators)\n",
    "               \n",
    "       \n",
    "                     \n",
    "#               y = df_encoded['Approved_Flag']\n",
    "#               x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "#               label_encoder = LabelEncoder()\n",
    "#               y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "#               x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#               model.fit(x_train, y_train)\n",
    "  \n",
    "\n",
    "       \n",
    "#               # Predict on training and testing sets\n",
    "#               y_pred_train = model.predict(x_train)\n",
    "#               y_pred_test = model.predict(x_test)\n",
    "       \n",
    "       \n",
    "#               # Calculate train and test results\n",
    "              \n",
    "#               train_accuracy =  accuracy_score (y_train, y_pred_train)\n",
    "#               test_accuracy  =  accuracy_score (y_test , y_pred_test)\n",
    "              \n",
    "              \n",
    "       \n",
    "#               # Include into the lists\n",
    "#               answers_grid ['combination']   .append(index)\n",
    "#               answers_grid ['train_Accuracy']    .append(train_accuracy)\n",
    "#               answers_grid ['test_Accuracy']     .append(test_accuracy)\n",
    "#               answers_grid ['colsample_bytree']   .append(colsample_bytree)\n",
    "#               answers_grid ['learning_rate']      .append(learning_rate)\n",
    "#               answers_grid ['max_depth']          .append(max_depth)\n",
    "#               answers_grid ['alpha']              .append(alpha)\n",
    "#               answers_grid ['n_estimators']       .append(n_estimators)\n",
    "       \n",
    "       \n",
    "#               # Print results for this combination\n",
    "#               print(f\"Combination {index}\")\n",
    "#               print(f\"colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth: {max_depth}, alpha: {alpha}, n_estimators: {n_estimators}\")\n",
    "#               print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "#               print(f\"Test Accuracy : {test_accuracy :.2f}\")\n",
    "#               print(\"-\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "811a72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert answers_grid into a DataFrame\n",
    "# answers_df = pd.DataFrame(answers_grid)\n",
    "\n",
    "# # Find the row with the best (highest) test accuracy\n",
    "# best_row = answers_df.loc[answers_df['test_Accuracy'].idxmax()]\n",
    "\n",
    "# print(\" Best Hyperparameter Combination:\")\n",
    "# print(f\"Combination #: {int(best_row['combination'])}\")\n",
    "# print(f\"Train Accuracy: {best_row['train_Accuracy']:.4f}\")\n",
    "# print(f\"Test Accuracy : {best_row['test_Accuracy']:.4f}\")\n",
    "# print(f\"colsample_bytree: {best_row['colsample_bytree']}\")\n",
    "# print(f\"learning_rate  : {best_row['learning_rate']}\")\n",
    "# print(f\"max_depth      : {int(best_row['max_depth'])}\")\n",
    "# print(f\"alpha          : {best_row['alpha']}\")\n",
    "# print(f\"n_estimators   : {int(best_row['n_estimators'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7dc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
