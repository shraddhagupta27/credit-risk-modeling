{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9140122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "55960359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "\n",
    "df1 = pd.read_excel('case_study1.xlsx')\n",
    "\n",
    "df2 = pd.read_excel('case_study2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b2bcc7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 26)\n",
      "(51336, 62)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "74b0928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51296, 26)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove nulls\n",
    "\n",
    "df1 = df1[df1['Age_Newest_TL'] != -99999]\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ce82403d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_since_first_deliquency',\n",
       " 'time_since_recent_deliquency',\n",
       " 'max_delinquency_level',\n",
       " 'max_deliq_6mts',\n",
       " 'max_deliq_12mts',\n",
       " 'CC_utilization',\n",
       " 'PL_utilization',\n",
       " 'max_unsec_exposure_inPct']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns with more than 10k null values \n",
    "\n",
    "cols_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        cols_removed.append(i)\n",
    "\n",
    "cols_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eb90800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51336, 54)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove cols with null values\n",
    "\n",
    "df2 = df2.drop(cols_removed, axis=1)\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "93846d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42066, 54)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove null rows\n",
    "\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[df2[i] != -99999]\n",
    "\n",
    "df2.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4da5b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID\n"
     ]
    }
   ],
   "source": [
    "# checking commom columns\n",
    "\n",
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d7b45815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42064, 79)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join both datasets\n",
    "\n",
    "df = df1.merge(df2, how='inner', on='PROSPECTID')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1362101f-4d1f-4c3c-8ae0-d588cb3f533b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROSPECTID</th>\n",
       "      <th>Total_TL</th>\n",
       "      <th>Tot_Closed_TL</th>\n",
       "      <th>Tot_Active_TL</th>\n",
       "      <th>Total_TL_opened_L6M</th>\n",
       "      <th>Tot_TL_closed_L6M</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>pct_active_tl</th>\n",
       "      <th>pct_closed_tl</th>\n",
       "      <th>Total_TL_opened_L12M</th>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <th>pct_tl_open_L12M</th>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <th>Auto_TL</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Consumer_TL</th>\n",
       "      <th>Gold_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>Unsecured_TL</th>\n",
       "      <th>Other_TL</th>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <th>Age_Newest_TL</th>\n",
       "      <th>time_since_recent_payment</th>\n",
       "      <th>num_times_delinquent</th>\n",
       "      <th>max_recent_level_of_deliq</th>\n",
       "      <th>num_deliq_6mts</th>\n",
       "      <th>num_deliq_12mts</th>\n",
       "      <th>num_deliq_6_12mts</th>\n",
       "      <th>num_times_30p_dpd</th>\n",
       "      <th>num_times_60p_dpd</th>\n",
       "      <th>num_std</th>\n",
       "      <th>num_std_6mts</th>\n",
       "      <th>num_std_12mts</th>\n",
       "      <th>num_sub</th>\n",
       "      <th>num_sub_6mts</th>\n",
       "      <th>num_sub_12mts</th>\n",
       "      <th>num_dbt</th>\n",
       "      <th>num_dbt_6mts</th>\n",
       "      <th>num_dbt_12mts</th>\n",
       "      <th>num_lss</th>\n",
       "      <th>num_lss_6mts</th>\n",
       "      <th>num_lss_12mts</th>\n",
       "      <th>recent_level_of_deliq</th>\n",
       "      <th>tot_enq</th>\n",
       "      <th>CC_enq</th>\n",
       "      <th>CC_enq_L6m</th>\n",
       "      <th>CC_enq_L12m</th>\n",
       "      <th>PL_enq</th>\n",
       "      <th>PL_enq_L6m</th>\n",
       "      <th>PL_enq_L12m</th>\n",
       "      <th>time_since_recent_enq</th>\n",
       "      <th>enq_L12m</th>\n",
       "      <th>enq_L6m</th>\n",
       "      <th>enq_L3m</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NETMONTHLYINCOME</th>\n",
       "      <th>Time_With_Curr_Empr</th>\n",
       "      <th>pct_of_active_TLs_ever</th>\n",
       "      <th>pct_opened_TLs_L6m_of_L12m</th>\n",
       "      <th>pct_currentBal_all_TL</th>\n",
       "      <th>CC_Flag</th>\n",
       "      <th>PL_Flag</th>\n",
       "      <th>pct_PL_enq_L6m_of_L12m</th>\n",
       "      <th>pct_CC_enq_L6m_of_L12m</th>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <th>HL_Flag</th>\n",
       "      <th>GL_Flag</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.00000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.00000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.00000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>4.206400e+04</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "      <td>42064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25649.827477</td>\n",
       "      <td>5.262980</td>\n",
       "      <td>2.967383</td>\n",
       "      <td>2.295597</td>\n",
       "      <td>0.812643</td>\n",
       "      <td>0.48992</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.097783</td>\n",
       "      <td>0.577452</td>\n",
       "      <td>0.422548</td>\n",
       "      <td>1.672142</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>0.401271</td>\n",
       "      <td>0.160365</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>0.667626</td>\n",
       "      <td>0.145921</td>\n",
       "      <td>1.362400</td>\n",
       "      <td>1.566304</td>\n",
       "      <td>0.076241</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>2.921334</td>\n",
       "      <td>2.341646</td>\n",
       "      <td>1.116489</td>\n",
       "      <td>46.498074</td>\n",
       "      <td>13.970046</td>\n",
       "      <td>218.601607</td>\n",
       "      <td>1.742939</td>\n",
       "      <td>14.314758</td>\n",
       "      <td>0.21163</td>\n",
       "      <td>0.548593</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>0.773298</td>\n",
       "      <td>0.438879</td>\n",
       "      <td>9.118343</td>\n",
       "      <td>1.464887</td>\n",
       "      <td>3.279978</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.02451</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>11.803918</td>\n",
       "      <td>5.457303</td>\n",
       "      <td>0.485641</td>\n",
       "      <td>0.162277</td>\n",
       "      <td>0.268924</td>\n",
       "      <td>1.174971</td>\n",
       "      <td>0.516927</td>\n",
       "      <td>0.779194</td>\n",
       "      <td>264.854507</td>\n",
       "      <td>3.063189</td>\n",
       "      <td>2.002686</td>\n",
       "      <td>1.230458</td>\n",
       "      <td>33.752472</td>\n",
       "      <td>2.692990e+04</td>\n",
       "      <td>110.345783</td>\n",
       "      <td>0.577452</td>\n",
       "      <td>0.309198</td>\n",
       "      <td>0.883693</td>\n",
       "      <td>0.102962</td>\n",
       "      <td>0.193063</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>0.074833</td>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.064186</td>\n",
       "      <td>0.252235</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>679.326336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14844.173396</td>\n",
       "      <td>7.463383</td>\n",
       "      <td>6.141098</td>\n",
       "      <td>2.404086</td>\n",
       "      <td>1.383559</td>\n",
       "      <td>1.05892</td>\n",
       "      <td>0.278043</td>\n",
       "      <td>0.210957</td>\n",
       "      <td>0.366110</td>\n",
       "      <td>0.366110</td>\n",
       "      <td>2.249543</td>\n",
       "      <td>1.537208</td>\n",
       "      <td>0.381266</td>\n",
       "      <td>0.258831</td>\n",
       "      <td>1.106442</td>\n",
       "      <td>0.952677</td>\n",
       "      <td>0.549314</td>\n",
       "      <td>2.394966</td>\n",
       "      <td>5.500184</td>\n",
       "      <td>0.358582</td>\n",
       "      <td>0.916368</td>\n",
       "      <td>6.379764</td>\n",
       "      <td>3.405397</td>\n",
       "      <td>2.486801</td>\n",
       "      <td>42.109230</td>\n",
       "      <td>18.835191</td>\n",
       "      <td>422.282417</td>\n",
       "      <td>4.390599</td>\n",
       "      <td>54.056303</td>\n",
       "      <td>0.75794</td>\n",
       "      <td>1.625512</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>2.860464</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>21.514144</td>\n",
       "      <td>3.375811</td>\n",
       "      <td>7.566312</td>\n",
       "      <td>0.799989</td>\n",
       "      <td>0.081704</td>\n",
       "      <td>0.220786</td>\n",
       "      <td>0.62189</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.573762</td>\n",
       "      <td>0.083310</td>\n",
       "      <td>0.204293</td>\n",
       "      <td>46.422091</td>\n",
       "      <td>6.308943</td>\n",
       "      <td>1.710479</td>\n",
       "      <td>0.681683</td>\n",
       "      <td>1.019459</td>\n",
       "      <td>2.380981</td>\n",
       "      <td>1.373240</td>\n",
       "      <td>1.802092</td>\n",
       "      <td>466.585002</td>\n",
       "      <td>4.299207</td>\n",
       "      <td>3.165782</td>\n",
       "      <td>2.069461</td>\n",
       "      <td>8.774652</td>\n",
       "      <td>2.084300e+04</td>\n",
       "      <td>75.629967</td>\n",
       "      <td>0.366110</td>\n",
       "      <td>0.400555</td>\n",
       "      <td>40.622275</td>\n",
       "      <td>0.303913</td>\n",
       "      <td>0.394707</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.250658</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.231042</td>\n",
       "      <td>21.133619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12776.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000e+04</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25706.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.400000e+04</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>679.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38518.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.100000e+04</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>51336.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>6065.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4768.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6327.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>809.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PROSPECTID      Total_TL  Tot_Closed_TL  Tot_Active_TL  \\\n",
       "count  42064.000000  42064.000000   42064.000000   42064.000000   \n",
       "mean   25649.827477      5.262980       2.967383       2.295597   \n",
       "std    14844.173396      7.463383       6.141098       2.404086   \n",
       "min        1.000000      1.000000       0.000000       0.000000   \n",
       "25%    12776.750000      1.000000       0.000000       1.000000   \n",
       "50%    25706.500000      3.000000       1.000000       2.000000   \n",
       "75%    38518.250000      6.000000       3.000000       3.000000   \n",
       "max    51336.000000    235.000000     216.000000      47.000000   \n",
       "\n",
       "       Total_TL_opened_L6M  Tot_TL_closed_L6M  pct_tl_open_L6M  \\\n",
       "count         42064.000000        42064.00000     42064.000000   \n",
       "mean              0.812643            0.48992         0.179032   \n",
       "std               1.383559            1.05892         0.278043   \n",
       "min               0.000000            0.00000         0.000000   \n",
       "25%               0.000000            0.00000         0.000000   \n",
       "50%               0.000000            0.00000         0.000000   \n",
       "75%               1.000000            1.00000         0.333000   \n",
       "max              27.000000           19.00000         1.000000   \n",
       "\n",
       "       pct_tl_closed_L6M  pct_active_tl  pct_closed_tl  Total_TL_opened_L12M  \\\n",
       "count       42064.000000   42064.000000   42064.000000          42064.000000   \n",
       "mean            0.097783       0.577452       0.422548              1.672142   \n",
       "std             0.210957       0.366110       0.366110              2.249543   \n",
       "min             0.000000       0.000000       0.000000              0.000000   \n",
       "25%             0.000000       0.286000       0.000000              0.000000   \n",
       "50%             0.000000       0.545000       0.455000              1.000000   \n",
       "75%             0.100000       1.000000       0.714000              2.000000   \n",
       "max             1.000000       1.000000       1.000000             34.000000   \n",
       "\n",
       "       Tot_TL_closed_L12M  pct_tl_open_L12M  pct_tl_closed_L12M  \\\n",
       "count        42064.000000      42064.000000        42064.000000   \n",
       "mean             0.825504          0.401271            0.160365   \n",
       "std              1.537208          0.381266            0.258831   \n",
       "min              0.000000          0.000000            0.000000   \n",
       "25%              0.000000          0.000000            0.000000   \n",
       "50%              0.000000          0.333000            0.000000   \n",
       "75%              1.000000          0.714000            0.250000   \n",
       "max             33.000000          1.000000            1.000000   \n",
       "\n",
       "       Tot_Missed_Pmnt       Auto_TL         CC_TL   Consumer_TL  \\\n",
       "count     42064.000000  42064.000000  42064.000000  42064.000000   \n",
       "mean          0.525746      0.667626      0.145921      1.362400   \n",
       "std           1.106442      0.952677      0.549314      2.394966   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      0.000000   \n",
       "50%           0.000000      0.000000      0.000000      1.000000   \n",
       "75%           1.000000      1.000000      0.000000      2.000000   \n",
       "max          34.000000     27.000000     27.000000     41.000000   \n",
       "\n",
       "            Gold_TL       Home_TL         PL_TL    Secured_TL  Unsecured_TL  \\\n",
       "count  42064.000000  42064.000000  42064.000000  42064.000000  42064.000000   \n",
       "mean       1.566304      0.076241      0.328000      2.921334      2.341646   \n",
       "std        5.500184      0.358582      0.916368      6.379764      3.405397   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "75%        1.000000      0.000000      0.000000      3.000000      3.000000   \n",
       "max      235.000000     10.000000     29.000000    235.000000     55.000000   \n",
       "\n",
       "           Other_TL  Age_Oldest_TL  Age_Newest_TL  time_since_recent_payment  \\\n",
       "count  42064.000000   42064.000000   42064.000000               42064.000000   \n",
       "mean       1.116489      46.498074      13.970046                 218.601607   \n",
       "std        2.486801      42.109230      18.835191                 422.282417   \n",
       "min        0.000000       0.000000       0.000000                   2.000000   \n",
       "25%        0.000000      14.000000       4.000000                  51.000000   \n",
       "50%        0.000000      34.000000       7.000000                  71.000000   \n",
       "75%        1.000000      65.000000      16.000000                 146.000000   \n",
       "max       80.000000     385.000000     359.000000                6065.000000   \n",
       "\n",
       "       num_times_delinquent  max_recent_level_of_deliq  num_deliq_6mts  \\\n",
       "count          42064.000000               42064.000000     42064.00000   \n",
       "mean               1.742939                  14.314758         0.21163   \n",
       "std                4.390599                  54.056303         0.75794   \n",
       "min                0.000000                   0.000000         0.00000   \n",
       "25%                0.000000                   0.000000         0.00000   \n",
       "50%                0.000000                   0.000000         0.00000   \n",
       "75%                1.000000                  15.000000         0.00000   \n",
       "max               74.000000                 900.000000        12.00000   \n",
       "\n",
       "       num_deliq_12mts  num_deliq_6_12mts  num_times_30p_dpd  \\\n",
       "count     42064.000000       42064.000000       42064.000000   \n",
       "mean          0.548593           0.336963           0.773298   \n",
       "std           1.625512           1.097356           2.860464   \n",
       "min           0.000000           0.000000           0.000000   \n",
       "25%           0.000000           0.000000           0.000000   \n",
       "50%           0.000000           0.000000           0.000000   \n",
       "75%           0.000000           0.000000           0.000000   \n",
       "max          28.000000          20.000000          60.000000   \n",
       "\n",
       "       num_times_60p_dpd       num_std  num_std_6mts  num_std_12mts  \\\n",
       "count       42064.000000  42064.000000  42064.000000   42064.000000   \n",
       "mean            0.438879      9.118343      1.464887       3.279978   \n",
       "std             2.148400     21.514144      3.375811       7.566312   \n",
       "min             0.000000      0.000000      0.000000       0.000000   \n",
       "25%             0.000000      0.000000      0.000000       0.000000   \n",
       "50%             0.000000      0.000000      0.000000       0.000000   \n",
       "75%             0.000000      8.000000      1.000000       3.000000   \n",
       "max            52.000000    422.000000     58.000000     122.000000   \n",
       "\n",
       "            num_sub  num_sub_6mts  num_sub_12mts      num_dbt  num_dbt_6mts  \\\n",
       "count  42064.000000  42064.000000   42064.000000  42064.00000  42064.000000   \n",
       "mean       0.063831      0.002211       0.009224      0.02451      0.001284   \n",
       "std        0.799989      0.081704       0.220786      0.62189      0.072637   \n",
       "min        0.000000      0.000000       0.000000      0.00000      0.000000   \n",
       "25%        0.000000      0.000000       0.000000      0.00000      0.000000   \n",
       "50%        0.000000      0.000000       0.000000      0.00000      0.000000   \n",
       "75%        0.000000      0.000000       0.000000      0.00000      0.000000   \n",
       "max       41.000000      5.000000      12.000000     35.00000      6.000000   \n",
       "\n",
       "       num_dbt_12mts       num_lss  num_lss_6mts  num_lss_12mts  \\\n",
       "count   42064.000000  42064.000000  42064.000000   42064.000000   \n",
       "mean        0.004279      0.016713      0.001189       0.003376   \n",
       "std         0.184461      0.573762      0.083310       0.204293   \n",
       "min         0.000000      0.000000      0.000000       0.000000   \n",
       "25%         0.000000      0.000000      0.000000       0.000000   \n",
       "50%         0.000000      0.000000      0.000000       0.000000   \n",
       "75%         0.000000      0.000000      0.000000       0.000000   \n",
       "max        12.000000     72.000000     12.000000      30.000000   \n",
       "\n",
       "       recent_level_of_deliq       tot_enq        CC_enq    CC_enq_L6m  \\\n",
       "count           42064.000000  42064.000000  42064.000000  42064.000000   \n",
       "mean               11.803918      5.457303      0.485641      0.162277   \n",
       "std                46.422091      6.308943      1.710479      0.681683   \n",
       "min                 0.000000      1.000000      0.000000      0.000000   \n",
       "25%                 0.000000      2.000000      0.000000      0.000000   \n",
       "50%                 0.000000      3.000000      0.000000      0.000000   \n",
       "75%                11.000000      7.000000      0.000000      0.000000   \n",
       "max               900.000000    176.000000     42.000000     17.000000   \n",
       "\n",
       "        CC_enq_L12m        PL_enq    PL_enq_L6m   PL_enq_L12m  \\\n",
       "count  42064.000000  42064.000000  42064.000000  42064.000000   \n",
       "mean       0.268924      1.174971      0.516927      0.779194   \n",
       "std        1.019459      2.380981      1.373240      1.802092   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      1.000000   \n",
       "max       24.000000     46.000000     44.000000     44.000000   \n",
       "\n",
       "       time_since_recent_enq      enq_L12m       enq_L6m       enq_L3m  \\\n",
       "count           42064.000000  42064.000000  42064.000000  42064.000000   \n",
       "mean              264.854507      3.063189      2.002686      1.230458   \n",
       "std               466.585002      4.299207      3.165782      2.069461   \n",
       "min                 0.000000      0.000000      0.000000      0.000000   \n",
       "25%                 9.000000      1.000000      0.000000      0.000000   \n",
       "50%                79.000000      2.000000      1.000000      1.000000   \n",
       "75%               302.000000      4.000000      3.000000      2.000000   \n",
       "max              4768.000000     87.000000     66.000000     42.000000   \n",
       "\n",
       "                AGE  NETMONTHLYINCOME  Time_With_Curr_Empr  \\\n",
       "count  42064.000000      4.206400e+04         42064.000000   \n",
       "mean      33.752472      2.692990e+04           110.345783   \n",
       "std        8.774652      2.084300e+04            75.629967   \n",
       "min       21.000000      0.000000e+00             0.000000   \n",
       "25%       27.000000      1.800000e+04            61.000000   \n",
       "50%       32.000000      2.400000e+04            92.000000   \n",
       "75%       39.000000      3.100000e+04           131.000000   \n",
       "max       67.000000      2.500000e+06          1020.000000   \n",
       "\n",
       "       pct_of_active_TLs_ever  pct_opened_TLs_L6m_of_L12m  \\\n",
       "count            42064.000000                42064.000000   \n",
       "mean                 0.577452                    0.309198   \n",
       "std                  0.366110                    0.400555   \n",
       "min                  0.000000                    0.000000   \n",
       "25%                  0.286000                    0.000000   \n",
       "50%                  0.545000                    0.000000   \n",
       "75%                  1.000000                    0.625000   \n",
       "max                  1.000000                    1.000000   \n",
       "\n",
       "       pct_currentBal_all_TL       CC_Flag       PL_Flag  \\\n",
       "count           42064.000000  42064.000000  42064.000000   \n",
       "mean                0.883693      0.102962      0.193063   \n",
       "std                40.622275      0.303913      0.394707   \n",
       "min                 0.000000      0.000000      0.000000   \n",
       "25%                 0.152000      0.000000      0.000000   \n",
       "50%                 0.600000      0.000000      0.000000   \n",
       "75%                 0.860000      0.000000      0.000000   \n",
       "max              6327.500000      1.000000      1.000000   \n",
       "\n",
       "       pct_PL_enq_L6m_of_L12m  pct_CC_enq_L6m_of_L12m  pct_PL_enq_L6m_of_ever  \\\n",
       "count            42064.000000            42064.000000            42064.000000   \n",
       "mean                 0.219169                0.074833                0.195497   \n",
       "std                  0.395100                0.250658                0.367414   \n",
       "min                  0.000000                0.000000                0.000000   \n",
       "25%                  0.000000                0.000000                0.000000   \n",
       "50%                  0.000000                0.000000                0.000000   \n",
       "75%                  0.000000                0.000000                0.000000   \n",
       "max                  1.000000                1.000000                1.000000   \n",
       "\n",
       "       pct_CC_enq_L6m_of_ever       HL_Flag       GL_Flag  Credit_Score  \n",
       "count            42064.000000  42064.000000  42064.000000  42064.000000  \n",
       "mean                 0.064186      0.252235      0.056580    679.326336  \n",
       "std                  0.225989      0.434300      0.231042     21.133619  \n",
       "min                  0.000000      0.000000      0.000000    469.000000  \n",
       "25%                  0.000000      0.000000      0.000000    668.000000  \n",
       "50%                  0.000000      0.000000      0.000000    679.000000  \n",
       "75%                  0.000000      1.000000      0.000000    690.000000  \n",
       "max                  1.000000      1.000000      1.000000    809.000000  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "15d360e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "# check categorical columns\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "794a17c8-31b2-48fe-9dc3-0e048d6928a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Single']\n",
      "['12TH' 'GRADUATE' 'SSC' 'POST-GRADUATE' 'UNDER GRADUATE' 'OTHERS'\n",
      " 'PROFESSIONAL']\n",
      "['M' 'F']\n",
      "['PL' 'ConsumerLoan' 'AL' 'CC' 'others' 'HL']\n",
      "['PL' 'ConsumerLoan' 'others' 'AL' 'HL' 'CC']\n",
      "['P2' 'P1' 'P3' 'P4']\n"
     ]
    }
   ],
   "source": [
    "print(df['MARITALSTATUS'].unique())\n",
    "print(df['EDUCATION'].unique())\n",
    "print(df['GENDER'].unique())\n",
    "print(df['last_prod_enq2'].unique())\n",
    "print(df['first_prod_enq2'].unique())\n",
    "print(df['Approved_Flag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84efd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.5781808610388605e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.9079361001865664e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.849976105554191e-287\n"
     ]
    }
   ],
   "source": [
    "# chi-square test \n",
    "\n",
    "# for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "#     chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "#     print(i, \"---\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7a0af8a7-b300-4619-9bf1-c31275506103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS        | p-value: 3.5782e-233 | Cramér’s V: 0.1600\n",
      "EDUCATION            | p-value: 2.6942e-30 | Cramér’s V: 0.0386\n",
      "GENDER               | p-value: 1.9079e-05 | Cramér’s V: 0.0242\n",
      "last_prod_enq2       | p-value: 0.0000e+00 | Cramér’s V: 0.1392\n",
      "first_prod_enq2      | p-value: 7.8500e-287 | Cramér’s V: 0.1049\n"
     ]
    }
   ],
   "source": [
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(chi2 / (n * (min(r, k) - 1)))\n",
    "\n",
    "cols = ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "\n",
    "for col in cols:\n",
    "    ct = pd.crosstab(df[col], df['Approved_Flag'])\n",
    "    chi2, pval, _, _ = chi2_contingency(ct)\n",
    "    v = cramers_v(ct)\n",
    "    print(f\"{col:20s} | p-value: {pval:.4e} | Cramér’s V: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "764afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all values less than equal to 0.05, we can accept all \n",
    "# but cramers v is less than 0.05 for eduaction and gender, so remove those \n",
    "# associated with target variable \n",
    "\n",
    "# check with both columns - xgboost - 77.26\n",
    "# check with education - 77.10\n",
    "# removed both - 77.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "71cd3b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total_TL',\n",
       " 'Tot_Closed_TL',\n",
       " 'Tot_Active_TL',\n",
       " 'Total_TL_opened_L6M',\n",
       " 'Tot_TL_closed_L6M',\n",
       " 'pct_tl_open_L6M',\n",
       " 'pct_tl_closed_L6M',\n",
       " 'pct_active_tl',\n",
       " 'pct_closed_tl',\n",
       " 'Total_TL_opened_L12M',\n",
       " 'Tot_TL_closed_L12M',\n",
       " 'pct_tl_open_L12M',\n",
       " 'pct_tl_closed_L12M',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'Auto_TL',\n",
       " 'CC_TL',\n",
       " 'Consumer_TL',\n",
       " 'Gold_TL',\n",
       " 'Home_TL',\n",
       " 'PL_TL',\n",
       " 'Secured_TL',\n",
       " 'Unsecured_TL',\n",
       " 'Other_TL',\n",
       " 'Age_Oldest_TL',\n",
       " 'Age_Newest_TL',\n",
       " 'time_since_recent_payment',\n",
       " 'num_times_delinquent',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'num_deliq_6mts',\n",
       " 'num_deliq_12mts',\n",
       " 'num_deliq_6_12mts',\n",
       " 'num_times_30p_dpd',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_std',\n",
       " 'num_std_6mts',\n",
       " 'num_std_12mts',\n",
       " 'num_sub',\n",
       " 'num_sub_6mts',\n",
       " 'num_sub_12mts',\n",
       " 'num_dbt',\n",
       " 'num_dbt_6mts',\n",
       " 'num_dbt_12mts',\n",
       " 'num_lss',\n",
       " 'num_lss_6mts',\n",
       " 'num_lss_12mts',\n",
       " 'recent_level_of_deliq',\n",
       " 'tot_enq',\n",
       " 'CC_enq',\n",
       " 'CC_enq_L6m',\n",
       " 'CC_enq_L12m',\n",
       " 'PL_enq',\n",
       " 'PL_enq_L6m',\n",
       " 'PL_enq_L12m',\n",
       " 'time_since_recent_enq',\n",
       " 'enq_L12m',\n",
       " 'enq_L6m',\n",
       " 'enq_L3m',\n",
       " 'AGE',\n",
       " 'NETMONTHLYINCOME',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'pct_of_active_TLs_ever',\n",
       " 'pct_opened_TLs_L6m_of_L12m',\n",
       " 'pct_currentBal_all_TL',\n",
       " 'CC_Flag',\n",
       " 'PL_Flag',\n",
       " 'pct_PL_enq_L6m_of_L12m',\n",
       " 'pct_CC_enq_L6m_of_L12m',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'HL_Flag',\n",
       " 'GL_Flag',\n",
       " 'Credit_Score']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check numerical columns\n",
    "\n",
    "num_cols = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID', 'Approved_Flag']:\n",
    "        num_cols.append(i)\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "018344e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- inf\n",
      "0 --- 11.320180023967982\n",
      "0 --- 8.36369803500036\n",
      "0 --- 6.5206478777909425\n",
      "0 --- 5.14950161821261\n",
      "1 --- 2.611111040579735\n",
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477212\n",
      "2 --- 3.832800792153082\n",
      "3 --- 6.0996533816466405\n",
      "3 --- 5.581352009642814\n",
      "4 --- 1.9855843530987702\n",
      "5 --- inf\n",
      "5 --- 4.809538302819332\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588099946\n",
      "6 --- 4.384346405965575\n",
      "7 --- 3.0646584155234122\n",
      "8 --- 2.898639771299225\n",
      "9 --- 4.377876915347337\n",
      "10 --- 2.2078535836958486\n",
      "11 --- 4.916914200506877\n",
      "12 --- 5.214702030064743\n",
      "13 --- 3.3861625024231516\n",
      "14 --- 7.84058330947899\n",
      "14 --- 5.255034641721459\n",
      "15 --- inf\n",
      "15 --- 7.380634506427207\n",
      "15 --- 1.421005001517572\n",
      "16 --- 8.083255010190301\n",
      "16 --- 1.6241227524040012\n",
      "17 --- 7.257811920140015\n",
      "17 --- 15.596243832683006\n",
      "17 --- 1.825857047132431\n",
      "18 --- 1.5080839450032724\n",
      "19 --- 2.1720888348245815\n",
      "20 --- 2.6233975535272367\n",
      "21 --- 2.2959970812106216\n",
      "22 --- 7.360578319196457\n",
      "22 --- 2.1602387773102514\n",
      "23 --- 2.8686288267891493\n",
      "24 --- 6.458218003637239\n",
      "24 --- 2.847411886563821\n",
      "25 --- 4.753198156284062\n",
      "26 --- 16.22735475594819\n",
      "26 --- 6.424377256363831\n",
      "26 --- 8.887080381808696\n",
      "26 --- 2.3804746142952564\n",
      "27 --- 8.609513476514524\n",
      "27 --- 13.067550935476769\n",
      "27 --- 3.500040056654664\n",
      "28 --- 1.908795587481377\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.73048515371916\n",
      "29 --- 2.3538497522950457\n",
      "30 --- 22.104855915136543\n",
      "30 --- 2.797163963851296\n",
      "31 --- 3.4241712032177065\n",
      "32 --- 10.17502145445105\n",
      "32 --- 6.408710354561287\n",
      "32 --- 1.0011511962625617\n",
      "33 --- 3.06919730539727\n",
      "34 --- 2.8091261600643707\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593886\n",
      "35 --- 1.8331649740532123\n",
      "36 --- 1.5680839909542181\n",
      "37 --- 1.930757235381163\n",
      "38 --- 4.33126505664525\n",
      "39 --- 9.390334396150184\n"
     ]
    }
   ],
   "source": [
    "# VIF sequentially check\n",
    "\n",
    "vif_data = df[num_cols]\n",
    "total_cols = vif_data.shape[1]\n",
    "cols_to_keep = []\n",
    "col_index = 0\n",
    "\n",
    "for i in range(0, total_cols):\n",
    "    vif_value = variance_inflation_factor(vif_data, col_index)\n",
    "    print(col_index, \"---\", vif_value)\n",
    "\n",
    "    if vif_value <= 6:\n",
    "        cols_to_keep.append(num_cols[i])\n",
    "        col_index = col_index + 1\n",
    "\n",
    "    else: \n",
    "        vif_data = vif_data.drop(num_cols[i], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "44a627ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7636086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check anova\n",
    "\n",
    "# cols_to_keep_num = []\n",
    "\n",
    "# for i in cols_to_keep:\n",
    "#     a = list(df[i])\n",
    "#     b = list(df['Approved_Flag'])\n",
    "\n",
    "#     group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "#     group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "#     group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "#     group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "#     f_statistics, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "#     if p_value <= 0.05:\n",
    "#         cols_to_keep_num.append(i)\n",
    "\n",
    "\n",
    "# len(cols_to_keep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dfc05938-0134-479f-860e-adeb65cfa648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>H_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>epsilon_sq</th>\n",
       "      <th>n_nonnull</th>\n",
       "      <th>n_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enq_L3m</td>\n",
       "      <td>12633.712184</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.300302</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Oldest_TL</td>\n",
       "      <td>9390.306137</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.223188</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pct_PL_enq_L6m_of_ever</td>\n",
       "      <td>7281.843002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.173059</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_since_recent_enq</td>\n",
       "      <td>7121.527996</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.169247</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_std_12mts</td>\n",
       "      <td>5665.151268</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.134621</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PL_enq_L12m</td>\n",
       "      <td>5300.178109</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.125943</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Secured_TL</td>\n",
       "      <td>3443.148288</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.081791</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recent_level_of_deliq</td>\n",
       "      <td>2081.218221</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.049411</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pct_CC_enq_L6m_of_ever</td>\n",
       "      <td>1956.247275</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.046440</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_recent_level_of_deliq</td>\n",
       "      <td>1943.979023</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.046148</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Other_TL</td>\n",
       "      <td>1821.033761</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CC_enq_L12m</td>\n",
       "      <td>1620.273511</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Home_TL</td>\n",
       "      <td>1499.183650</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GL_Flag</td>\n",
       "      <td>1468.839102</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pct_tl_open_L6M</td>\n",
       "      <td>1412.836263</td>\n",
       "      <td>4.828327e-306</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Time_With_Curr_Empr</td>\n",
       "      <td>1263.958904</td>\n",
       "      <td>9.726601e-274</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HL_Flag</td>\n",
       "      <td>1083.590795</td>\n",
       "      <td>1.321361e-234</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Age_Newest_TL</td>\n",
       "      <td>862.315540</td>\n",
       "      <td>1.320795e-186</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tot_Missed_Pmnt</td>\n",
       "      <td>797.218525</td>\n",
       "      <td>1.735679e-172</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PL_TL</td>\n",
       "      <td>769.844830</td>\n",
       "      <td>1.499767e-166</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Unsecured_TL</td>\n",
       "      <td>740.100668</td>\n",
       "      <td>4.230123e-160</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PL_Flag</td>\n",
       "      <td>668.493787</td>\n",
       "      <td>1.424150e-144</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num_times_60p_dpd</td>\n",
       "      <td>460.004506</td>\n",
       "      <td>2.215913e-99</td>\n",
       "      <td>0.010866</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>num_deliq_6_12mts</td>\n",
       "      <td>438.854063</td>\n",
       "      <td>8.474956e-95</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tot_TL_closed_L12M</td>\n",
       "      <td>376.026387</td>\n",
       "      <td>3.448317e-81</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pct_currentBal_all_TL</td>\n",
       "      <td>368.572976</td>\n",
       "      <td>1.418308e-79</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NETMONTHLYINCOME</td>\n",
       "      <td>354.743617</td>\n",
       "      <td>1.401260e-76</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CC_TL</td>\n",
       "      <td>242.291136</td>\n",
       "      <td>3.041155e-52</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CC_Flag</td>\n",
       "      <td>235.037801</td>\n",
       "      <td>1.125991e-50</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>num_sub</td>\n",
       "      <td>153.566036</td>\n",
       "      <td>4.481749e-33</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>time_since_recent_payment</td>\n",
       "      <td>127.427559</td>\n",
       "      <td>1.938196e-27</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pct_tl_closed_L6M</td>\n",
       "      <td>82.668034</td>\n",
       "      <td>8.215513e-18</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>num_dbt</td>\n",
       "      <td>81.423458</td>\n",
       "      <td>1.519408e-17</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pct_tl_closed_L12M</td>\n",
       "      <td>32.238345</td>\n",
       "      <td>4.661792e-07</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>num_sub_12mts</td>\n",
       "      <td>26.365089</td>\n",
       "      <td>7.997822e-06</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>num_dbt_12mts</td>\n",
       "      <td>19.573519</td>\n",
       "      <td>2.080333e-04</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>num_lss</td>\n",
       "      <td>18.056467</td>\n",
       "      <td>4.282108e-04</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>num_sub_6mts</td>\n",
       "      <td>16.211302</td>\n",
       "      <td>1.026293e-03</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>num_lss_12mts</td>\n",
       "      <td>5.345623</td>\n",
       "      <td>1.481692e-01</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>42064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature        H_stat        p_value  epsilon_sq  \\\n",
       "0                     enq_L3m  12633.712184   0.000000e+00    0.300302   \n",
       "1               Age_Oldest_TL   9390.306137   0.000000e+00    0.223188   \n",
       "2      pct_PL_enq_L6m_of_ever   7281.843002   0.000000e+00    0.173059   \n",
       "3       time_since_recent_enq   7121.527996   0.000000e+00    0.169247   \n",
       "4               num_std_12mts   5665.151268   0.000000e+00    0.134621   \n",
       "5                 PL_enq_L12m   5300.178109   0.000000e+00    0.125943   \n",
       "6                  Secured_TL   3443.148288   0.000000e+00    0.081791   \n",
       "7       recent_level_of_deliq   2081.218221   0.000000e+00    0.049411   \n",
       "8      pct_CC_enq_L6m_of_ever   1956.247275   0.000000e+00    0.046440   \n",
       "9   max_recent_level_of_deliq   1943.979023   0.000000e+00    0.046148   \n",
       "10                   Other_TL   1821.033761   0.000000e+00    0.043225   \n",
       "11                CC_enq_L12m   1620.273511   0.000000e+00    0.038452   \n",
       "12                    Home_TL   1499.183650   0.000000e+00    0.035573   \n",
       "13                    GL_Flag   1468.839102   0.000000e+00    0.034851   \n",
       "14            pct_tl_open_L6M   1412.836263  4.828327e-306    0.033520   \n",
       "15        Time_With_Curr_Empr   1263.958904  9.726601e-274    0.029980   \n",
       "16                    HL_Flag   1083.590795  1.321361e-234    0.025692   \n",
       "17              Age_Newest_TL    862.315540  1.320795e-186    0.020431   \n",
       "18            Tot_Missed_Pmnt    797.218525  1.735679e-172    0.018883   \n",
       "19                      PL_TL    769.844830  1.499767e-166    0.018232   \n",
       "20               Unsecured_TL    740.100668  4.230123e-160    0.017525   \n",
       "21                    PL_Flag    668.493787  1.424150e-144    0.015822   \n",
       "22          num_times_60p_dpd    460.004506   2.215913e-99    0.010866   \n",
       "23          num_deliq_6_12mts    438.854063   8.474956e-95    0.010363   \n",
       "24         Tot_TL_closed_L12M    376.026387   3.448317e-81    0.008869   \n",
       "25      pct_currentBal_all_TL    368.572976   1.418308e-79    0.008692   \n",
       "26           NETMONTHLYINCOME    354.743617   1.401260e-76    0.008363   \n",
       "27                      CC_TL    242.291136   3.041155e-52    0.005689   \n",
       "28                    CC_Flag    235.037801   1.125991e-50    0.005517   \n",
       "29                    num_sub    153.566036   4.481749e-33    0.003580   \n",
       "30  time_since_recent_payment    127.427559   1.938196e-27    0.002958   \n",
       "31          pct_tl_closed_L6M     82.668034   8.215513e-18    0.001894   \n",
       "32                    num_dbt     81.423458   1.519408e-17    0.001865   \n",
       "33         pct_tl_closed_L12M     32.238345   4.661792e-07    0.000695   \n",
       "34              num_sub_12mts     26.365089   7.997822e-06    0.000556   \n",
       "35              num_dbt_12mts     19.573519   2.080333e-04    0.000394   \n",
       "36                    num_lss     18.056467   4.282108e-04    0.000358   \n",
       "37               num_sub_6mts     16.211302   1.026293e-03    0.000314   \n",
       "38              num_lss_12mts      5.345623   1.481692e-01    0.000056   \n",
       "\n",
       "    n_nonnull  n_classes  \n",
       "0       42064          4  \n",
       "1       42064          4  \n",
       "2       42064          4  \n",
       "3       42064          4  \n",
       "4       42064          4  \n",
       "5       42064          4  \n",
       "6       42064          4  \n",
       "7       42064          4  \n",
       "8       42064          4  \n",
       "9       42064          4  \n",
       "10      42064          4  \n",
       "11      42064          4  \n",
       "12      42064          4  \n",
       "13      42064          4  \n",
       "14      42064          4  \n",
       "15      42064          4  \n",
       "16      42064          4  \n",
       "17      42064          4  \n",
       "18      42064          4  \n",
       "19      42064          4  \n",
       "20      42064          4  \n",
       "21      42064          4  \n",
       "22      42064          4  \n",
       "23      42064          4  \n",
       "24      42064          4  \n",
       "25      42064          4  \n",
       "26      42064          4  \n",
       "27      42064          4  \n",
       "28      42064          4  \n",
       "29      42064          4  \n",
       "30      42064          4  \n",
       "31      42064          4  \n",
       "32      42064          4  \n",
       "33      42064          4  \n",
       "34      42064          4  \n",
       "35      42064          4  \n",
       "36      42064          4  \n",
       "37      42064          4  \n",
       "38      42064          4  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "def kruskal_eps2(df, feature, target):\n",
    "    \"\"\"\n",
    "    Kruskal-Wallis test + epsilon-squared effect size for multi-class targets.\n",
    "    epsilon^2 ~ proportion of variability explained (nonparametric analogue).\n",
    "    \"\"\"\n",
    "    d = df[[feature, target]].dropna()\n",
    "\n",
    "    # Build samples per class\n",
    "    groups = [g[feature].values for _, g in d.groupby(target, sort=False)]\n",
    "    k = len(groups)\n",
    "    n = len(d)\n",
    "\n",
    "    # Need at least 2 non-empty groups\n",
    "    if k < 2 or n == 0:\n",
    "        return np.nan, np.nan, np.nan, n, k\n",
    "\n",
    "    H, p = kruskal(*groups)\n",
    "\n",
    "    # Epsilon-squared for Kruskal-Wallis:\n",
    "    # eps^2 = (H - k + 1) / (n - k)\n",
    "    # Clamp at 0 to avoid tiny negatives due to floating error\n",
    "    denom = (n - k)\n",
    "    eps2 = (H - k + 1) / denom if denom > 0 else np.nan\n",
    "    if not np.isnan(eps2):\n",
    "        eps2 = max(0.0, eps2)\n",
    "\n",
    "    return H, p, eps2, n, k\n",
    "\n",
    "\n",
    "def run_kruskal_multiclass_report(df, target_col, numeric_cols):\n",
    "    rows = []\n",
    "    for col in numeric_cols:\n",
    "        H, p, eps2, n, k = kruskal_eps2(df, col, target_col)\n",
    "        rows.append({\n",
    "            \"feature\": col,\n",
    "            \"H_stat\": H,\n",
    "            \"p_value\": p,\n",
    "            \"epsilon_sq\": eps2,\n",
    "            \"n_nonnull\": n,\n",
    "            \"n_classes\": k\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values([\"p_value\", \"epsilon_sq\"], ascending=[True, False])\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ---- Usage ----\n",
    "report = run_kruskal_multiclass_report(df, \"Approved_Flag\", cols_to_keep)\n",
    "\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e6144bb4-eae4-4d72-8a4b-836bd3571d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enq_L3m',\n",
       " 'Age_Oldest_TL',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'time_since_recent_enq',\n",
       " 'num_std_12mts',\n",
       " 'PL_enq_L12m',\n",
       " 'Secured_TL',\n",
       " 'recent_level_of_deliq',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'Other_TL',\n",
       " 'CC_enq_L12m',\n",
       " 'Home_TL',\n",
       " 'GL_Flag',\n",
       " 'pct_tl_open_L6M',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'HL_Flag',\n",
       " 'Age_Newest_TL',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'PL_TL',\n",
       " 'Unsecured_TL',\n",
       " 'PL_Flag',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_deliq_6_12mts']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = report.loc[report['epsilon_sq'] > 0.01, 'feature'].tolist()\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4b5e8166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42064, 28)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listing all the final features\n",
    "\n",
    "features = feat + ['MARITALSTATUS', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b9466464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding for education\n",
    "\n",
    "# df.loc[df['EDUCATION']=='SSC', ['EDUCATION']] = 1\n",
    "# df.loc[df['EDUCATION']=='12TH', ['EDUCATION']] = 2\n",
    "# df.loc[df['EDUCATION']=='UNDER GRADUATE', ['EDUCATION']] = 3\n",
    "# df.loc[df['EDUCATION']=='GRADUATE', ['EDUCATION']] = 3\n",
    "# df.loc[df['EDUCATION']=='POST-GRADUATE', ['EDUCATION']] = 4\n",
    "# df.loc[df['EDUCATION']=='PROFESSIONAL', ['EDUCATION']] = 3\n",
    "# df.loc[df['EDUCATION']=='OTHERS', ['EDUCATION']] = 1\n",
    "\n",
    "# df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "# df['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "abebfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 36 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   enq_L3m                       42064 non-null  int64  \n",
      " 1   Age_Oldest_TL                 42064 non-null  int64  \n",
      " 2   pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 3   time_since_recent_enq         42064 non-null  int64  \n",
      " 4   num_std_12mts                 42064 non-null  int64  \n",
      " 5   PL_enq_L12m                   42064 non-null  int64  \n",
      " 6   Secured_TL                    42064 non-null  int64  \n",
      " 7   recent_level_of_deliq         42064 non-null  int64  \n",
      " 8   pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 9   max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  CC_enq_L12m                   42064 non-null  int64  \n",
      " 12  Home_TL                       42064 non-null  int64  \n",
      " 13  GL_Flag                       42064 non-null  int64  \n",
      " 14  pct_tl_open_L6M               42064 non-null  float64\n",
      " 15  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 16  HL_Flag                       42064 non-null  int64  \n",
      " 17  Age_Newest_TL                 42064 non-null  int64  \n",
      " 18  Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 19  PL_TL                         42064 non-null  int64  \n",
      " 20  Unsecured_TL                  42064 non-null  int64  \n",
      " 21  PL_Flag                       42064 non-null  int64  \n",
      " 22  num_times_60p_dpd             42064 non-null  int64  \n",
      " 23  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 24  Approved_Flag                 42064 non-null  object \n",
      " 25  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 26  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 27  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 28  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 29  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 30  last_prod_enq2_others         42064 non-null  bool   \n",
      " 31  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 32  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 33  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 34  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 35  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(11), float64(3), int64(21), object(1)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding for other categorical columns\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS', 'last_prod_enq2', 'first_prod_enq2'], drop_first=True)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1d5b4393-abc3-41a4-b296-656d435a9894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['enq_L3m', 'Age_Oldest_TL', 'pct_PL_enq_L6m_of_ever',\n",
       "       'time_since_recent_enq', 'num_std_12mts', 'PL_enq_L12m', 'Secured_TL',\n",
       "       'recent_level_of_deliq', 'pct_CC_enq_L6m_of_ever',\n",
       "       'max_recent_level_of_deliq', 'Other_TL', 'CC_enq_L12m', 'Home_TL',\n",
       "       'GL_Flag', 'pct_tl_open_L6M', 'Time_With_Curr_Empr', 'HL_Flag',\n",
       "       'Age_Newest_TL', 'Tot_Missed_Pmnt', 'PL_TL', 'Unsecured_TL', 'PL_Flag',\n",
       "       'num_times_60p_dpd', 'num_deliq_6_12mts', 'Approved_Flag',\n",
       "       'MARITALSTATUS_Single', 'last_prod_enq2_CC',\n",
       "       'last_prod_enq2_ConsumerLoan', 'last_prod_enq2_HL', 'last_prod_enq2_PL',\n",
       "       'last_prod_enq2_others', 'first_prod_enq2_CC',\n",
       "       'first_prod_enq2_ConsumerLoan', 'first_prod_enq2_HL',\n",
       "       'first_prod_enq2_PL', 'first_prod_enq2_others'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "64238907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.764174491857839\n",
      "\n",
      "Class p1\n",
      "Precision = 0.8373702422145328\n",
      "Recall = 0.7159763313609467\n",
      "F1_score = 0.7719298245614035\n",
      "\n",
      "Class p2\n",
      "Precision = 0.802311540451958\n",
      "Recall = 0.9219028741328048\n",
      "F1_score = 0.85795978601734\n",
      "\n",
      "Class p3\n",
      "Precision = 0.4347202295552367\n",
      "Recall = 0.22867924528301886\n",
      "F1_score = 0.2997032640949555\n",
      "\n",
      "Class p4\n",
      "Precision = 0.7119771863117871\n",
      "Recall = 0.7278911564625851\n",
      "F1_score = 0.7198462277751081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "rf_classifier.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1b6b629f-e2a3-4a28-9174-2a5011094891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.7190062997741591\n",
      "\n",
      "Class p1\n",
      "Precision = 0.7224926971762414\n",
      "Recall = 0.7317554240631163\n",
      "F1_score = 0.7270945614894659\n",
      "\n",
      "Class p2\n",
      "Precision = 0.8159735717061796\n",
      "Recall = 0.8323092170465808\n",
      "F1_score = 0.8240604454911196\n",
      "\n",
      "Class p3\n",
      "Precision = 0.36356209150326796\n",
      "Recall = 0.33584905660377357\n",
      "F1_score = 0.34915653197332286\n",
      "\n",
      "Class p4\n",
      "Precision = 0.6525590551181102\n",
      "Recall = 0.6443148688046647\n",
      "F1_score = 0.6484107579462103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "\n",
    "dt_model.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dcb5795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.7722572209675502\n",
      "\n",
      "Class p1\n",
      "Precision = 0.8286637931034483\n",
      "Recall = 0.7583826429980276\n",
      "F1_score = 0.791967044284243\n",
      "\n",
      "Class p2\n",
      "Precision = 0.8232441171187354\n",
      "Recall = 0.9084241823587711\n",
      "F1_score = 0.8637391632114587\n",
      "\n",
      "Class p3\n",
      "Precision = 0.44680851063829785\n",
      "Recall = 0.3011320754716981\n",
      "F1_score = 0.35978358881875566\n",
      "\n",
      "Class p4\n",
      "Precision = 0.7278048780487805\n",
      "Recall = 0.7249757045675413\n",
      "F1_score = 0.7263875365141188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(x_trian, y_train)\n",
    "\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print()\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f'Class {v}')\n",
    "    print(f'Precision = {precision[i]}')\n",
    "    print(f'Recall = {recall[i]}')\n",
    "    print(f'F1_score = {f1_score[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "499ce65f-e42f-4d8d-aeb9-dcde95a15189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 01:29:35,604]\u001b[0m A new study created in memory with name: no-name-da4c7279-c0ad-4dc7-8bad-5cc2a0e06778\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:37,521]\u001b[0m Trial 0 finished with value: 0.7751099488886247 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 0 with value: 0.7751099488886247.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:38,223]\u001b[0m Trial 1 finished with value: 0.7519315345298943 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 0 with value: 0.7751099488886247.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:38,372]\u001b[0m Trial 2 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 100, 'n_estimators': 10}. Best is trial 0 with value: 0.7751099488886247.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:39,184]\u001b[0m Trial 3 finished with value: 0.7701176750267443 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 50}. Best is trial 0 with value: 0.7751099488886247.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:39,395]\u001b[0m Trial 4 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 6, 'alpha': 1, 'n_estimators': 10}. Best is trial 0 with value: 0.7751099488886247.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:40,712]\u001b[0m Trial 5 finished with value: 0.7514560798763817 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 100, 'n_estimators': 100}. Best is trial 0 with value: 0.7751099488886247.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:42,145]\u001b[0m Trial 6 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:42,685]\u001b[0m Trial 7 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 1, 'n_estimators': 50}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:44,013]\u001b[0m Trial 8 finished with value: 0.7751099488886247 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:45,113]\u001b[0m Trial 9 finished with value: 0.7165101628432188 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:46,550]\u001b[0m Trial 10 finished with value: 0.7512183525496255 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:47,680]\u001b[0m Trial 11 finished with value: 0.7749910852252466 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:48,894]\u001b[0m Trial 12 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:50,355]\u001b[0m Trial 13 finished with value: 0.7418281231427553 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:51,342]\u001b[0m Trial 14 finished with value: 0.7623915369071674 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 100, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:51,505]\u001b[0m Trial 15 finished with value: 0.7204326637346963 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 10}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:53,428]\u001b[0m Trial 16 finished with value: 0.7165101628432188 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:54,607]\u001b[0m Trial 17 finished with value: 0.7663140377986449 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:55,123]\u001b[0m Trial 18 finished with value: 0.6385355996671818 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'alpha': 10, 'n_estimators': 50}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:55,323]\u001b[0m Trial 19 finished with value: 0.6870319743254487 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 100, 'n_estimators': 10}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:56,531]\u001b[0m Trial 20 finished with value: 0.7715440389872816 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:58,058]\u001b[0m Trial 21 finished with value: 0.7751099488886247 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:29:59,255]\u001b[0m Trial 22 finished with value: 0.7751099488886247 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:00,522]\u001b[0m Trial 23 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:01,906]\u001b[0m Trial 24 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:03,039]\u001b[0m Trial 25 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:04,330]\u001b[0m Trial 26 finished with value: 0.7656008558183763 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:05,605]\u001b[0m Trial 27 finished with value: 0.738143349578034 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.01, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:06,190]\u001b[0m Trial 28 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.001, 'max_depth': 3, 'alpha': 100, 'n_estimators': 50}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:06,392]\u001b[0m Trial 29 finished with value: 0.7371924402710092 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 10}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:08,045]\u001b[0m Trial 30 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:10,713]\u001b[0m Trial 31 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:11,900]\u001b[0m Trial 32 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 6 with value: 0.7759419945322715.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:13,064]\u001b[0m Trial 33 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:15,535]\u001b[0m Trial 34 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:16,219]\u001b[0m Trial 35 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.001, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:16,400]\u001b[0m Trial 36 finished with value: 0.7457506240342328 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:17,303]\u001b[0m Trial 37 finished with value: 0.7692856293830976 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:18,865]\u001b[0m Trial 38 finished with value: 0.7717817663140378 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:19,669]\u001b[0m Trial 39 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.001, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:20,907]\u001b[0m Trial 40 finished with value: 0.7665517651254011 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 100, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:22,279]\u001b[0m Trial 41 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:23,561]\u001b[0m Trial 42 finished with value: 0.7759419945322715 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 1, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:25,657]\u001b[0m Trial 43 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:27,582]\u001b[0m Trial 44 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:28,982]\u001b[0m Trial 45 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:30,376]\u001b[0m Trial 46 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:31,848]\u001b[0m Trial 47 finished with value: 0.7433733507666707 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:32,035]\u001b[0m Trial 48 finished with value: 0.7457506240342328 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:32,995]\u001b[0m Trial 49 finished with value: 0.7692856293830976 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:34,441]\u001b[0m Trial 50 finished with value: 0.7678592654225603 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:35,683]\u001b[0m Trial 51 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:37,027]\u001b[0m Trial 52 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:38,192]\u001b[0m Trial 53 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:39,348]\u001b[0m Trial 54 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:41,358]\u001b[0m Trial 55 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:41,962]\u001b[0m Trial 56 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.001, 'max_depth': 5, 'alpha': 10, 'n_estimators': 50}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:43,217]\u001b[0m Trial 57 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:44,410]\u001b[0m Trial 58 finished with value: 0.7433733507666707 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:45,454]\u001b[0m Trial 59 finished with value: 0.7666706287887792 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 100, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:45,586]\u001b[0m Trial 60 finished with value: 0.7191251634375372 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 10, 'n_estimators': 10}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:46,774]\u001b[0m Trial 61 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:47,943]\u001b[0m Trial 62 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:48,920]\u001b[0m Trial 63 finished with value: 0.7165101628432188 and parameters: {'colsample_bytree': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:50,462]\u001b[0m Trial 64 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:51,817]\u001b[0m Trial 65 finished with value: 0.7761797218590277 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 100}. Best is trial 33 with value: 0.7761797218590277.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:53,240]\u001b[0m Trial 66 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:54,758]\u001b[0m Trial 67 finished with value: 0.7678592654225603 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:57,024]\u001b[0m Trial 68 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:57,613]\u001b[0m Trial 69 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 100, 'n_estimators': 50}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:30:58,956]\u001b[0m Trial 70 finished with value: 0.7512183525496255 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:00,471]\u001b[0m Trial 71 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:01,718]\u001b[0m Trial 72 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:02,967]\u001b[0m Trial 73 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:04,217]\u001b[0m Trial 74 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:05,455]\u001b[0m Trial 75 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:06,798]\u001b[0m Trial 76 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:07,039]\u001b[0m Trial 77 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.001, 'max_depth': 6, 'alpha': 10, 'n_estimators': 10}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:08,347]\u001b[0m Trial 78 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:09,834]\u001b[0m Trial 79 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:11,130]\u001b[0m Trial 80 finished with value: 0.7665517651254011 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 100, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:13,697]\u001b[0m Trial 81 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:15,051]\u001b[0m Trial 82 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:16,360]\u001b[0m Trial 83 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:17,777]\u001b[0m Trial 84 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:19,014]\u001b[0m Trial 85 finished with value: 0.7758231308688934 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:20,280]\u001b[0m Trial 86 finished with value: 0.7678592654225603 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:20,972]\u001b[0m Trial 87 finished with value: 0.7729704029478188 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 50}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:22,393]\u001b[0m Trial 88 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:23,722]\u001b[0m Trial 89 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:25,058]\u001b[0m Trial 90 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:26,363]\u001b[0m Trial 91 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:27,988]\u001b[0m Trial 92 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:30,349]\u001b[0m Trial 93 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:31,960]\u001b[0m Trial 94 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:33,342]\u001b[0m Trial 95 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.001, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:34,617]\u001b[0m Trial 96 finished with value: 0.7512183525496255 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:34,797]\u001b[0m Trial 97 finished with value: 0.755140853441103 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 10}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:36,140]\u001b[0m Trial 98 finished with value: 0.7758231308688934 and parameters: {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:37,414]\u001b[0m Trial 99 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:38,410]\u001b[0m Trial 100 finished with value: 0.752763580173541 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 100, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:39,650]\u001b[0m Trial 101 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:40,891]\u001b[0m Trial 102 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:42,164]\u001b[0m Trial 103 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:43,427]\u001b[0m Trial 104 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:45,775]\u001b[0m Trial 105 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:47,107]\u001b[0m Trial 106 finished with value: 0.7770117675026744 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:48,283]\u001b[0m Trial 107 finished with value: 0.7678592654225603 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 10, 'n_estimators': 100}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:49,073]\u001b[0m Trial 108 finished with value: 0.7729704029478188 and parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 10, 'n_estimators': 50}. Best is trial 66 with value: 0.7770117675026744.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:50,591]\u001b[0m Trial 109 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:51,843]\u001b[0m Trial 110 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:53,094]\u001b[0m Trial 111 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:54,351]\u001b[0m Trial 112 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:55,573]\u001b[0m Trial 113 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:56,794]\u001b[0m Trial 114 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:57,633]\u001b[0m Trial 115 finished with value: 0.7672649471056698 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:58,865]\u001b[0m Trial 116 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:31:59,037]\u001b[0m Trial 117 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 1, 'n_estimators': 10}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:01,370]\u001b[0m Trial 118 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:02,610]\u001b[0m Trial 119 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:03,788]\u001b[0m Trial 120 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:04,987]\u001b[0m Trial 121 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:06,179]\u001b[0m Trial 122 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:07,728]\u001b[0m Trial 123 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:09,427]\u001b[0m Trial 124 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:10,845]\u001b[0m Trial 125 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:12,106]\u001b[0m Trial 126 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:13,314]\u001b[0m Trial 127 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:14,038]\u001b[0m Trial 128 finished with value: 0.7672649471056698 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:15,309]\u001b[0m Trial 129 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:17,686]\u001b[0m Trial 130 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:18,882]\u001b[0m Trial 131 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:20,105]\u001b[0m Trial 132 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:21,324]\u001b[0m Trial 133 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:22,519]\u001b[0m Trial 134 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:23,162]\u001b[0m Trial 135 finished with value: 0.774277903244978 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 50}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:24,357]\u001b[0m Trial 136 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:25,564]\u001b[0m Trial 137 finished with value: 0.7628669915606799 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:26,750]\u001b[0m Trial 138 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:27,952]\u001b[0m Trial 139 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:29,143]\u001b[0m Trial 140 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:30,420]\u001b[0m Trial 141 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:31,838]\u001b[0m Trial 142 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:33,944]\u001b[0m Trial 143 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:35,272]\u001b[0m Trial 144 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:36,528]\u001b[0m Trial 145 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:37,750]\u001b[0m Trial 146 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:37,921]\u001b[0m Trial 147 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 1, 'n_estimators': 10}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:39,130]\u001b[0m Trial 148 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:40,351]\u001b[0m Trial 149 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:41,589]\u001b[0m Trial 150 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:42,807]\u001b[0m Trial 151 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:43,972]\u001b[0m Trial 152 finished with value: 0.7741590395815999 and parameters: {'colsample_bytree': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:45,168]\u001b[0m Trial 153 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:46,365]\u001b[0m Trial 154 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:47,133]\u001b[0m Trial 155 finished with value: 0.7672649471056698 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:49,575]\u001b[0m Trial 156 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:51,041]\u001b[0m Trial 157 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:52,323]\u001b[0m Trial 158 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:53,549]\u001b[0m Trial 159 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:54,188]\u001b[0m Trial 160 finished with value: 0.774277903244978 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 50}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:55,506]\u001b[0m Trial 161 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:57,073]\u001b[0m Trial 162 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:58,294]\u001b[0m Trial 163 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:32:59,543]\u001b[0m Trial 164 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:01,017]\u001b[0m Trial 165 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:02,253]\u001b[0m Trial 166 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:03,764]\u001b[0m Trial 167 finished with value: 0.7628669915606799 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:05,889]\u001b[0m Trial 168 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:07,457]\u001b[0m Trial 169 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:09,086]\u001b[0m Trial 170 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:10,716]\u001b[0m Trial 171 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:11,991]\u001b[0m Trial 172 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:13,254]\u001b[0m Trial 173 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:14,525]\u001b[0m Trial 174 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:15,751]\u001b[0m Trial 175 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:17,005]\u001b[0m Trial 176 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:17,177]\u001b[0m Trial 177 finished with value: 0.7280399381908951 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 10}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:17,974]\u001b[0m Trial 178 finished with value: 0.7672649471056698 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:19,265]\u001b[0m Trial 179 finished with value: 0.605016046594556 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:21,528]\u001b[0m Trial 180 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:22,738]\u001b[0m Trial 181 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:24,347]\u001b[0m Trial 182 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:25,569]\u001b[0m Trial 183 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:27,001]\u001b[0m Trial 184 finished with value: 0.726851301557114 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:28,194]\u001b[0m Trial 185 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:29,400]\u001b[0m Trial 186 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:30,635]\u001b[0m Trial 187 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:31,846]\u001b[0m Trial 188 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:32,944]\u001b[0m Trial 189 finished with value: 0.7625104005705455 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 100, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:34,201]\u001b[0m Trial 190 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:35,433]\u001b[0m Trial 191 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:37,367]\u001b[0m Trial 192 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:38,820]\u001b[0m Trial 193 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:40,727]\u001b[0m Trial 194 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:42,487]\u001b[0m Trial 195 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:44,174]\u001b[0m Trial 196 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:45,123]\u001b[0m Trial 197 finished with value: 0.774277903244978 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 50}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:46,892]\u001b[0m Trial 198 finished with value: 0.7786758587899679 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n",
      "\u001b[32m[I 2026-01-29 01:33:48,682]\u001b[0m Trial 199 finished with value: 0.7628669915606799 and parameters: {'colsample_bytree': 0.5, 'learning_rate': 1.0, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}. Best is trial 109 with value: 0.7786758587899679.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Accuracy : 0.7786758587899679\n",
      "Best Train Accuracy: 0.8148049092151793\n",
      "Best Parameters    : {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'alpha': 1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -------------------------\n",
    "# Prepare data ONCE\n",
    "# -------------------------\n",
    "y = df_encoded[\"Approved_Flag\"]\n",
    "X = df_encoded.drop(columns=[\"Approved_Flag\"])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_enc\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optuna objective\n",
    "# -------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softmax\",\n",
    "        \"num_class\": 4,\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 0.9, step=0.2),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.001, 0.01, 0.1, 1.0]),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", [3, 5, 6]),\n",
    "        \"reg_alpha\": trial.suggest_categorical(\"alpha\", [1, 10, 100]),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10, 50, 100]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"eval_metric\": \"mlogloss\"\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds  = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    test_acc  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "    # store train accuracy for the best trial\n",
    "    trial.set_user_attr(\"train_accuracy\", train_acc)\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "# -------------------------\n",
    "# Run optimization\n",
    "# -------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=False)\n",
    "\n",
    "# -------------------------\n",
    "# Print ONLY best result\n",
    "# -------------------------\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"Best Test Accuracy :\", best_trial.value)\n",
    "print(\"Best Train Accuracy:\", best_trial.user_attrs[\"train_accuracy\"])\n",
    "print(\"Best Parameters    :\", best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d09d2-d0f5-428f-be56-f67740587519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf484db9-1360-4b49-ab61-e112ce2f4620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c3b7639e-d87a-4508-9e08-de8826880011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply standard scaler \n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# columns_to_be_scaled = ['Age_Oldest_TL','Age_Newest_TL','time_since_recent_payment',\n",
    "# 'max_recent_level_of_deliq','recent_level_of_deliq',\n",
    "# 'time_since_recent_enq','NETMONTHLYINCOME','Time_With_Curr_Empr']\n",
    "\n",
    "# for i in columns_to_be_scaled:\n",
    "#     column_data = df_encoded[i].values.reshape(-1, 1)\n",
    "#     scaler = StandardScaler()\n",
    "#     scaled_column = scaler.fit_transform(column_data)\n",
    "#     df_encoded[i] = scaled_column\n",
    "\n",
    "# xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "# x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "# y = df_encoded['Approved_Flag']\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# x_trian, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# xgb_classifier.fit(x_trian, y_train)\n",
    "\n",
    "# y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print()\n",
    "# print(f'Accuracy = {accuracy}')\n",
    "# print()\n",
    "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "# for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "#     print(f'Class {v}')\n",
    "#     print(f'Precision = {precision[i]}')\n",
    "#     print(f'Recall = {recall[i]}')\n",
    "#     print(f'F1_score = {f1_score[i]}')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e11298a9-9608-4b04-88ae-da1d20867505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df_encoded[\"Approved_Flag\"]\n",
    "# X = df_encoded.drop(columns=[\"Approved_Flag\"])\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_enc = le.fit_transform(y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y_enc,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=y_enc\n",
    "# )\n",
    "\n",
    "# # -------------------------\n",
    "# # Optuna objective\n",
    "# # -------------------------\n",
    "# def objective(trial):\n",
    "\n",
    "#     params = {\n",
    "#         \"objective\": \"multi:softmax\",\n",
    "#         \"num_class\": 4,\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 0.9, step=0.2),\n",
    "#         \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.001, 0.01, 0.1, 1.0]),\n",
    "#         \"max_depth\": trial.suggest_categorical(\"max_depth\", [3, 5, 8, 10]),\n",
    "#         \"reg_alpha\": trial.suggest_categorical(\"alpha\", [1, 10, 100]),\n",
    "#         \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10, 50, 100]),\n",
    "#         \"random_state\": 42,\n",
    "#         \"n_jobs\": -1,\n",
    "#         \"eval_metric\": \"mlogloss\"\n",
    "#     }\n",
    "\n",
    "#     model = xgb.XGBClassifier(**params)\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     train_preds = model.predict(X_train)\n",
    "#     test_preds  = model.predict(X_test)\n",
    "\n",
    "#     train_acc = accuracy_score(y_train, train_preds)\n",
    "#     test_acc  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "#     # store train accuracy for the best trial\n",
    "#     trial.set_user_attr(\"train_accuracy\", train_acc)\n",
    "\n",
    "#     return test_acc\n",
    "\n",
    "# # -------------------------\n",
    "# # Run optimization\n",
    "# # -------------------------\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=200, show_progress_bar=False)\n",
    "\n",
    "# # -------------------------\n",
    "# # Print ONLY best result\n",
    "# # -------------------------\n",
    "# best_trial = study.best_trial\n",
    "\n",
    "# print(\"Best Test Accuracy :\", best_trial.value)\n",
    "# print(\"Best Train Accuracy:\", best_trial.user_attrs[\"train_accuracy\"])\n",
    "# print(\"Best Parameters    :\", best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e30bc-3f87-457d-9e81-74283e21ea27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29e0dc-14d1-450c-8a96-8bcff5935edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6439c-670c-46a2-b2eb-e384befcd61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e46c0-a941-4848-9664-6d57243d0a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b04dac90-cdbf-4434-aa2a-671967e60daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 42)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for unseen data\n",
    "\n",
    "un = pd.read_excel('/Users/shraddhagupta/Downloads/Unseen_Dataset.xlsx')\n",
    "un.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "04f70cf4-a193-4020-8c1e-91c6ce501ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 48 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               100 non-null    float64\n",
      " 1   pct_tl_closed_L6M             100 non-null    float64\n",
      " 2   Tot_TL_closed_L12M            100 non-null    int64  \n",
      " 3   pct_tl_closed_L12M            100 non-null    float64\n",
      " 4   Tot_Missed_Pmnt               100 non-null    int64  \n",
      " 5   CC_TL                         100 non-null    int64  \n",
      " 6   Home_TL                       100 non-null    int64  \n",
      " 7   PL_TL                         100 non-null    int64  \n",
      " 8   Secured_TL                    100 non-null    int64  \n",
      " 9   Unsecured_TL                  100 non-null    int64  \n",
      " 10  Other_TL                      100 non-null    int64  \n",
      " 11  Age_Oldest_TL                 100 non-null    int64  \n",
      " 12  Age_Newest_TL                 100 non-null    int64  \n",
      " 13  time_since_recent_payment     100 non-null    int64  \n",
      " 14  max_recent_level_of_deliq     100 non-null    int64  \n",
      " 15  num_deliq_6_12mts             100 non-null    int64  \n",
      " 16  num_times_60p_dpd             100 non-null    int64  \n",
      " 17  num_std_12mts                 100 non-null    int64  \n",
      " 18  num_sub                       100 non-null    int64  \n",
      " 19  num_sub_6mts                  100 non-null    int64  \n",
      " 20  num_sub_12mts                 100 non-null    int64  \n",
      " 21  num_dbt                       100 non-null    int64  \n",
      " 22  num_dbt_12mts                 100 non-null    int64  \n",
      " 23  num_lss                       100 non-null    int64  \n",
      " 24  recent_level_of_deliq         100 non-null    int64  \n",
      " 25  CC_enq_L12m                   100 non-null    int64  \n",
      " 26  PL_enq_L12m                   100 non-null    int64  \n",
      " 27  time_since_recent_enq         100 non-null    int64  \n",
      " 28  enq_L3m                       100 non-null    int64  \n",
      " 29  NETMONTHLYINCOME              100 non-null    int64  \n",
      " 30  Time_With_Curr_Empr           100 non-null    int64  \n",
      " 31  CC_Flag                       100 non-null    int64  \n",
      " 32  PL_Flag                       100 non-null    int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        100 non-null    float64\n",
      " 34  pct_CC_enq_L6m_of_ever        100 non-null    float64\n",
      " 35  HL_Flag                       100 non-null    int64  \n",
      " 36  GL_Flag                       100 non-null    int64  \n",
      " 37  MARITALSTATUS_Single          100 non-null    bool   \n",
      " 38  last_prod_enq2_CC             100 non-null    bool   \n",
      " 39  last_prod_enq2_ConsumerLoan   100 non-null    bool   \n",
      " 40  last_prod_enq2_HL             100 non-null    bool   \n",
      " 41  last_prod_enq2_PL             100 non-null    bool   \n",
      " 42  last_prod_enq2_others         100 non-null    bool   \n",
      " 43  first_prod_enq2_CC            100 non-null    bool   \n",
      " 44  first_prod_enq2_ConsumerLoan  100 non-null    bool   \n",
      " 45  first_prod_enq2_HL            100 non-null    bool   \n",
      " 46  first_prod_enq2_PL            100 non-null    bool   \n",
      " 47  first_prod_enq2_others        100 non-null    bool   \n",
      "dtypes: bool(11), float64(5), int64(32)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "# ordinal encoding for education\n",
    "\n",
    "# un.loc[un['EDUCATION']=='SSC', ['EDUCATION']] = 1\n",
    "# un.loc[un['EDUCATION']=='12TH', ['EDUCATION']] = 2\n",
    "# un.loc[un['EDUCATION']=='UNDER GRADUATE', ['EDUCATION']] = 3\n",
    "# un.loc[un['EDUCATION']=='GRADUATE', ['EDUCATION']] = 3\n",
    "# un.loc[un['EDUCATION']=='POST-GRADUATE', ['EDUCATION']] = 4\n",
    "# un.loc[un['EDUCATION']=='PROFESSIONAL', ['EDUCATION']] = 3\n",
    "# un.loc[un['EDUCATION']=='OTHERS', ['EDUCATION']] = 1\n",
    "\n",
    "# un['EDUCATION'] = un['EDUCATION'].astype(int)\n",
    "\n",
    "\n",
    "# one-hot encoding for other categorical columns\n",
    "\n",
    "\n",
    "df_unseen = pd.get_dummies(un, columns=['MARITALSTATUS', 'last_prod_enq2', 'first_prod_enq2'], drop_first=True)\n",
    "df_unseen.drop(columns=['EDUCATION', 'GENDER'], inplace=True)\n",
    "df_unseen.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "54270e8a-c866-430e-b9e2-ed3e8a1d8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen = df_unseen[['enq_L3m', 'Age_Oldest_TL', 'pct_PL_enq_L6m_of_ever',\n",
    "       'time_since_recent_enq', 'num_std_12mts', 'PL_enq_L12m', 'Secured_TL',\n",
    "       'recent_level_of_deliq', 'pct_CC_enq_L6m_of_ever',\n",
    "       'max_recent_level_of_deliq', 'Other_TL', 'CC_enq_L12m', 'Home_TL',\n",
    "       'GL_Flag', 'pct_tl_open_L6M', 'Time_With_Curr_Empr', 'HL_Flag',\n",
    "       'Age_Newest_TL', 'Tot_Missed_Pmnt', 'PL_TL', 'Unsecured_TL', 'PL_Flag',\n",
    "       'num_times_60p_dpd', 'num_deliq_6_12mts', \n",
    "       'MARITALSTATUS_Single', 'last_prod_enq2_CC',\n",
    "       'last_prod_enq2_ConsumerLoan', 'last_prod_enq2_HL', 'last_prod_enq2_PL',\n",
    "       'last_prod_enq2_others', 'first_prod_enq2_CC',\n",
    "       'first_prod_enq2_ConsumerLoan', 'first_prod_enq2_HL',\n",
    "       'first_prod_enq2_PL', 'first_prod_enq2_others']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7f4ebdfc-65b4-4b89-8033-f28669e74d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=4, \n",
    "                         colsample_bytree=0.5, learning_rate=0.1,\n",
    "                         max_depth=6, alpha=1, n_estimators=100)\n",
    "\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "y = df_encoded['Approved_Flag']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_trian, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(x_trian, y_train)\n",
    "\n",
    "y_pred_unseen = model.predict(df_unseen)\n",
    "\n",
    "df_unseen['Target'] = y_pred_unseen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2e742d29-860c-4936-ae58-9f43916b1ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_v\n",
       "P2    75\n",
       "P4    12\n",
       "P1     7\n",
       "P3     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(y_pred_unseen)\n",
    "df_unseen['Target_v'] = y_pred\n",
    "\n",
    "df_unseen['Target_v'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cada4-902d-4120-ba0b-03d169f4fa70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf8f1d-e33c-4129-b7f2-004c0bced180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58034682-bbe1-41d9-ace1-ec36ace5f99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c2f93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#   'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#   'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
    "#   'max_depth'       : [3, 5, 8, 10],\n",
    "#   'alpha'           : [1, 10, 100],\n",
    "#   'n_estimators'    : [10,50,100]\n",
    "# }\n",
    "\n",
    "# index = 0\n",
    "\n",
    "# answers_grid = {\n",
    "#     'combination'       :[],\n",
    "#     'train_Accuracy'    :[],\n",
    "#     'test_Accuracy'     :[],\n",
    "#     'colsample_bytree'  :[],\n",
    "#     'learning_rate'     :[],\n",
    "#     'max_depth'         :[],\n",
    "#     'alpha'             :[],\n",
    "#     'n_estimators'      :[]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Loop through each combination of hyperparameters\n",
    "# for colsample_bytree in param_grid['colsample_bytree']:\n",
    "#   for learning_rate in param_grid['learning_rate']:\n",
    "#     for max_depth in param_grid['max_depth']:\n",
    "#       for alpha in param_grid['alpha']:\n",
    "#           for n_estimators in param_grid['n_estimators']:\n",
    "             \n",
    "#               index = index + 1\n",
    "             \n",
    "#               # Define and train the XGBoost model\n",
    "#               model = xgb.XGBClassifier(objective='multi:softmax',  \n",
    "#                                        num_class=4,\n",
    "#                                        colsample_bytree = colsample_bytree,\n",
    "#                                        learning_rate = learning_rate,\n",
    "#                                        max_depth = max_depth,\n",
    "#                                        alpha = alpha,\n",
    "#                                        n_estimators = n_estimators)\n",
    "               \n",
    "       \n",
    "                     \n",
    "#               y = df_encoded['Approved_Flag']\n",
    "#               x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "#               label_encoder = LabelEncoder()\n",
    "#               y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "#               x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#               model.fit(x_train, y_train)\n",
    "  \n",
    "\n",
    "       \n",
    "#               # Predict on training and testing sets\n",
    "#               y_pred_train = model.predict(x_train)\n",
    "#               y_pred_test = model.predict(x_test)\n",
    "       \n",
    "       \n",
    "#               # Calculate train and test results\n",
    "              \n",
    "#               train_accuracy =  accuracy_score (y_train, y_pred_train)\n",
    "#               test_accuracy  =  accuracy_score (y_test , y_pred_test)\n",
    "              \n",
    "              \n",
    "       \n",
    "#               # Include into the lists\n",
    "#               answers_grid ['combination']   .append(index)\n",
    "#               answers_grid ['train_Accuracy']    .append(train_accuracy)\n",
    "#               answers_grid ['test_Accuracy']     .append(test_accuracy)\n",
    "#               answers_grid ['colsample_bytree']   .append(colsample_bytree)\n",
    "#               answers_grid ['learning_rate']      .append(learning_rate)\n",
    "#               answers_grid ['max_depth']          .append(max_depth)\n",
    "#               answers_grid ['alpha']              .append(alpha)\n",
    "#               answers_grid ['n_estimators']       .append(n_estimators)\n",
    "       \n",
    "       \n",
    "#               # Print results for this combination\n",
    "#               print(f\"Combination {index}\")\n",
    "#               print(f\"colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth: {max_depth}, alpha: {alpha}, n_estimators: {n_estimators}\")\n",
    "#               print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "#               print(f\"Test Accuracy : {test_accuracy :.2f}\")\n",
    "#               print(\"-\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "811a72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert answers_grid into a DataFrame\n",
    "# answers_df = pd.DataFrame(answers_grid)\n",
    "\n",
    "# # Find the row with the best (highest) test accuracy\n",
    "# best_row = answers_df.loc[answers_df['test_Accuracy'].idxmax()]\n",
    "\n",
    "# print(\"✅ Best Hyperparameter Combination:\")\n",
    "# print(f\"Combination #: {int(best_row['combination'])}\")\n",
    "# print(f\"Train Accuracy: {best_row['train_Accuracy']:.4f}\")\n",
    "# print(f\"Test Accuracy : {best_row['test_Accuracy']:.4f}\")\n",
    "# print(f\"colsample_bytree: {best_row['colsample_bytree']}\")\n",
    "# print(f\"learning_rate  : {best_row['learning_rate']}\")\n",
    "# print(f\"max_depth      : {int(best_row['max_depth'])}\")\n",
    "# print(f\"alpha          : {best_row['alpha']}\")\n",
    "# print(f\"n_estimators   : {int(best_row['n_estimators'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7dc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
